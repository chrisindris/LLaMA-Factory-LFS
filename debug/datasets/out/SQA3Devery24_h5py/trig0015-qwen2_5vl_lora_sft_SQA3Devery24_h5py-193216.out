WARNING: Environment variable PYTHONPATH already has value [/scratch/indrisch/LLaMA-Factory/src:/cvmfs/soft.computecanada.ca/custom/python/site-packages], will not forward new value [/cvmfs/soft.computecanada.ca/custom/python/site-packages] from parent process environment

==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[INFO|2026-01-09 05:43:53] llamafactory.launcher:143 >> Initializing 1 distributed tasks at: 127.0.0.1:60403
⚙️  Running in WANDB offline mode
[2026-01-09 05:44:00,249] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[2026-01-09 05:44:05,438] [INFO] [comm.py:669:init_distributed] cdb=None
[2026-01-09 05:44:05,438] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[INFO|2026-01-09 05:44:05] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2026-01-09 05:44:05] llamafactory.hparams.parser:455 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|hub.py:421] 2026-01-09 05:44:05,476 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2026-01-09 05:44:05,492 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,502 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2026-01-09 05:44:05,707 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2026-01-09 05:44:05,708 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2026-01-09 05:44:05,709 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2026-01-09 05:44:05,711 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2026-01-09 05:44:05,714 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:316] 2026-01-09 05:44:05,716 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2026-01-09 05:44:05,717 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:428] 2026-01-09 05:44:05,724 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2026-01-09 05:44:05,724 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2026-01-09 05:44:05,727 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2026-01-09 05:44:05,888 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2026-01-09 05:44:05,890 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2026-01-09 05:44:05,893 >> loading configuration file video_preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2026-01-09 05:44:05,896 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2026-01-09 05:44:05,896 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2026-01-09 05:44:05,902 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2026-01-09 05:44:06,189 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

[INFO|2026-01-09 05:44:06] llamafactory.data.loader:143 >> Loading dataset /scratch/indrisch/huggingface/hub/datasets--cvis-tmu--llamafactory-sqa3d-traces-multiimage-vqa/snapshots/ce5c54adc1608d1726730c9ff334e65b6dd70e46/data/...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/100 [00:02<?, ? examples/s]
[rank0]: multiprocess.pool.RemoteTraceback: 
[rank0]: """
[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/mm_plugin.py", line 266, in _regularize_images
[rank0]:     image = Image.open(image)
[rank0]:             ^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/PIL/Image.py", line 3469, in open
[rank0]:     fp = builtins.open(filename, "rb")
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: FileNotFoundError: [Errno 2] No such file or directory: '/scratch/indrisch/LLaMA-Factory/ScanNet/scans/scene0119_00/color/0.jpg'

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/mm_plugin.py", line 269, in _regularize_images
[rank0]:     image = retrieve_image(image_path=image)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/data_packing/h5py_data.py", line 309, in retrieve_image
[rank0]:     raise FileNotFoundError(error_msg)
[rank0]: FileNotFoundError: Scene directory does not exist: ScanNet/scans/scene0119_00

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/multiprocess/pool.py", line 125, in worker
[rank0]:     result = (True, func(*args, **kwds))
[rank0]:                     ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 586, in _write_generator_to_queue
[rank0]:     for i, result in enumerate(func(**kwargs)):
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3674, in _map_single
[rank0]:     for i, batch in iter_outputs(shard_iterable):
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3624, in iter_outputs
[rank0]:     yield i, apply_function(example, i, offset=offset)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3547, in apply_function
[rank0]:     processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/processor/supervised.py", line 99, in preprocess_dataset
[rank0]:     input_ids, labels = self._encode_data_example(
[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/processor/supervised.py", line 43, in _encode_data_example
[rank0]:     messages = self.template.mm_plugin.process_messages(prompt + response, images, videos, audios, self.processor)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/mm_plugin.py", line 1534, in process_messages
[rank0]:     mm_inputs = self._get_mm_inputs(images, videos, audios, processor)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/mm_plugin.py", line 1495, in _get_mm_inputs
[rank0]:     images = self._regularize_images(
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/mm_plugin.py", line 272, in _regularize_images
[rank0]:     raise ValueError(f"Failed to retrieve image from {image}: {e}")
[rank0]: ValueError: Failed to retrieve image from ScanNet/scans/scene0119_00/color/0.jpg: Scene directory does not exist: ScanNet/scans/scene0119_00
[rank0]: """

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/launcher.py", line 184, in <module>
[rank0]:     run_exp()
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/train/tuner.py", line 122, in run_exp
[rank0]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/train/tuner.py", line 84, in _training_function
[rank0]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank0]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/loader.py", line 316, in get_dataset
[rank0]:     dataset = _get_preprocessed_dataset(
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/data/loader.py", line 257, in _get_preprocessed_dataset
[rank0]:     dataset = dataset.map(
[rank0]:               ^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[rank0]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[rank0]:                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3309, in map
[rank0]:     for rank, done, content in iflatmap_unordered(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 626, in iflatmap_unordered
[rank0]:     [async_result.get(timeout=0.05) for async_result in async_results]
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 626, in <listcomp>
[rank0]:     [async_result.get(timeout=0.05) for async_result in async_results]
[rank0]:      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/multiprocess/pool.py", line 774, in get
[rank0]:     raise self._value
[rank0]: ValueError: Failed to retrieve image from ScanNet/scans/scene0119_00/color/0.jpg: Scene directory does not exist: ScanNet/scans/scene0119_00
[rank0]:[W109 05:44:10.026510528 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
E0109 05:44:11.821000 818909 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 818940) of binary: /opt/conda/bin/python3.11
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/scratch/indrisch/LLaMA-Factory/src/llamafactory/launcher.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-09_05:44:11
  host      : trig0015.scinet.local
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 818940)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/scratch/indrisch/LLaMA-Factory/src/llamafactory/launcher.py", line 114, in launch
    process = subprocess.run(
              ^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['torchrun', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '1', '--master_addr', '127.0.0.1', '--master_port', '60403', '/scratch/indrisch/LLaMA-Factory/src/llamafactory/launcher.py', '/scratch/indrisch/LLaMA-Factory/examples/train_lora/qwen2_5vl_lora_sft_SQA3Devery24_h5py.yaml']' returned non-zero exit status 1.

scontrol show job 193216
JobId=193216 JobName=slurm_qwen2_5vl_lora_sft_SQA3Devery24_h5py.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=118755 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:40 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2026-01-09T05:39:32 EligibleTime=2026-01-09T05:39:32
   AccrueTime=2026-01-09T05:39:32
   StartTime=2026-01-09T05:43:33 EndTime=2026-01-09T05:44:13 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2026-01-09T05:43:33 Scheduler=Backfill
   Partition=compute AllocNode:Sid=trig-login01:237667
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0015
   BatchHost=trig0015
   NumNodes=1 NumCPUs=24 NumTasks=1 CPUs/Task=24 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=24,mem=192500M,node=1,billing=1,gres/gpu=1
   AllocTRES=cpu=24,mem=192500M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=24 MinMemoryNode=192500M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/debug/datasets/slurm_qwen2_5vl_lora_sft_SQA3Devery24_h5py.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/debug/datasets
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L slurm_qwen2_5vl_lora_sft_SQA3Devery24_h5py.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/debug/datasets/out/SQA3Devery24_h5py/%N-qwen2_5vl_lora_sft_SQA3Devery24_h5py-193216.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/debug/datasets/out/SQA3Devery24_h5py/%N-qwen2_5vl_lora_sft_SQA3Devery24_h5py-193216.out
   TresPerNode=gres/gpu:h100:1
   TresPerTask=cpu=24
   

sacct -j 193216
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
193216       slurm_qwe+ def-wangcs   00:00:40                         00:00:00   00:00:00      0:0 
193216.batch      batch def-wangcs   00:00:40                         00:00:00   00:00:00      0:0 
193216.exte+     extern def-wangcs   00:00:40                         00:00:00   00:00:00      0:0 

