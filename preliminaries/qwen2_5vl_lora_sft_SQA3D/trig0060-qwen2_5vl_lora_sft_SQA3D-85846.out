
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[2025-11-13 01:14:20,586] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[INFO|2025-11-13 01:14:23] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16
[INFO|hub.py:421] 2025-11-13 01:14:23,504 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2025-11-13 01:14:23,518 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,528 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-13 01:14:23,734 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2025-11-13 01:14:23,735 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2025-11-13 01:14:23,736 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2025-11-13 01:14:23,738 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-13 01:14:23,740 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:316] 2025-11-13 01:14:23,742 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-13 01:14:23,744 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-11-13 01:14:23,751 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2025-11-13 01:14:23,751 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 01:14:23,755 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-13 01:14:23,918 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2025-11-13 01:14:23,920 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2025-11-13 01:14:23,922 >> loading configuration file video_preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-11-13 01:14:23,925 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-11-13 01:14:23,925 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2025-11-13 01:14:23,930 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2025-11-13 01:14:24,221 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

[INFO|2025-11-13 01:14:24] llamafactory.data.loader:143 >> Loading dataset /scratch/indrisch/huggingface/hub/datasets--cvis-tmu--llamafactory-sqa3d-traces-multiimage-vqa/snapshots/57a4793962153e37fb77a681f2a8d0b685539997/data/...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Converting format of dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   0%|          | 1/1000 [00:00<08:03,  2.07 examples/s]Converting format of dataset (num_proc=16):   0%|          | 4/1000 [00:00<01:58,  8.38 examples/s]Converting format of dataset (num_proc=16):   1%|          | 6/1000 [00:00<01:32, 10.75 examples/s]Converting format of dataset (num_proc=16):   1%|          | 9/1000 [00:00<01:15, 13.18 examples/s]Converting format of dataset (num_proc=16):   1%|▏         | 13/1000 [00:00<00:53, 18.48 examples/s]Converting format of dataset (num_proc=16):   2%|▏         | 16/1000 [00:01<00:49, 19.73 examples/s]Converting format of dataset (num_proc=16):   2%|▏         | 21/1000 [00:01<00:43, 22.69 examples/s]Converting format of dataset (num_proc=16):   2%|▏         | 24/1000 [00:01<00:44, 22.11 examples/s]Converting format of dataset (num_proc=16):   3%|▎         | 29/1000 [00:01<00:39, 24.30 examples/s]Converting format of dataset (num_proc=16):   3%|▎         | 32/1000 [00:01<00:47, 20.39 examples/s]Converting format of dataset (num_proc=16):   4%|▎         | 37/1000 [00:02<00:42, 22.88 examples/s]Converting format of dataset (num_proc=16):   4%|▍         | 40/1000 [00:02<00:43, 22.05 examples/s]Converting format of dataset (num_proc=16):   4%|▍         | 44/1000 [00:02<00:40, 23.84 examples/s]Converting format of dataset (num_proc=16):   5%|▍         | 47/1000 [00:02<00:40, 23.32 examples/s]Converting format of dataset (num_proc=16):   5%|▌         | 50/1000 [00:02<00:44, 21.59 examples/s]Converting format of dataset (num_proc=16):   5%|▌         | 53/1000 [00:02<00:42, 22.23 examples/s]Converting format of dataset (num_proc=16):   6%|▌         | 56/1000 [00:02<00:44, 21.34 examples/s]Converting format of dataset (num_proc=16):   6%|▌         | 62/1000 [00:03<00:31, 29.43 examples/s]Converting format of dataset (num_proc=16):   7%|▋         | 66/1000 [00:03<00:37, 24.99 examples/s]Converting format of dataset (num_proc=16):   7%|▋         | 70/1000 [00:03<00:33, 27.44 examples/s]Converting format of dataset (num_proc=16):   7%|▋         | 74/1000 [00:03<00:38, 24.29 examples/s]Converting format of dataset (num_proc=16):   8%|▊         | 78/1000 [00:03<00:38, 23.98 examples/s]Converting format of dataset (num_proc=16):   8%|▊         | 81/1000 [00:03<00:43, 21.22 examples/s]Converting format of dataset (num_proc=16):   9%|▊         | 87/1000 [00:04<00:36, 25.02 examples/s]Converting format of dataset (num_proc=16):   9%|▉         | 93/1000 [00:04<00:31, 28.85 examples/s]Converting format of dataset (num_proc=16):  10%|▉         | 96/1000 [00:04<00:31, 28.69 examples/s]Converting format of dataset (num_proc=16):  10%|▉         | 99/1000 [00:04<00:31, 28.46 examples/s]Converting format of dataset (num_proc=16):  10%|█         | 102/1000 [00:04<00:47, 18.89 examples/s]Converting format of dataset (num_proc=16):  10%|█         | 105/1000 [00:04<00:45, 19.54 examples/s]Converting format of dataset (num_proc=16):  11%|█         | 108/1000 [00:05<00:44, 20.05 examples/s]Converting format of dataset (num_proc=16):  11%|█▏        | 113/1000 [00:05<00:38, 23.30 examples/s]Converting format of dataset (num_proc=16):  12%|█▏        | 118/1000 [00:05<00:34, 25.66 examples/s]Converting format of dataset (num_proc=16):  12%|█▏        | 122/1000 [00:05<00:31, 28.30 examples/s]Converting format of dataset (num_proc=16):  13%|█▎        | 126/1000 [00:05<00:30, 28.36 examples/s]Converting format of dataset (num_proc=16):  13%|█▎        | 131/1000 [00:05<00:27, 31.51 examples/s]Converting format of dataset (num_proc=16):  14%|█▎        | 136/1000 [00:05<00:26, 32.62 examples/s]Converting format of dataset (num_proc=16):  14%|█▍        | 140/1000 [00:06<00:26, 32.47 examples/s]Converting format of dataset (num_proc=16):  15%|█▍        | 147/1000 [00:06<00:23, 36.50 examples/s]Converting format of dataset (num_proc=16):  15%|█▌        | 151/1000 [00:06<00:23, 36.56 examples/s]Converting format of dataset (num_proc=16):  16%|█▌        | 155/1000 [00:06<00:22, 36.92 examples/s]Converting format of dataset (num_proc=16):  16%|█▋        | 163/1000 [00:06<00:18, 45.76 examples/s]Converting format of dataset (num_proc=16):  17%|█▋        | 168/1000 [00:06<00:26, 31.68 examples/s]Converting format of dataset (num_proc=16):  17%|█▋        | 172/1000 [00:06<00:27, 29.83 examples/s]Converting format of dataset (num_proc=16):  18%|█▊        | 176/1000 [00:07<00:29, 28.14 examples/s]Converting format of dataset (num_proc=16):  18%|█▊        | 180/1000 [00:07<00:27, 30.30 examples/s]Converting format of dataset (num_proc=16):  18%|█▊        | 184/1000 [00:07<00:28, 28.74 examples/s]Converting format of dataset (num_proc=16):  19%|█▉        | 188/1000 [00:07<00:26, 30.45 examples/s]Converting format of dataset (num_proc=16):  19%|█▉        | 192/1000 [00:07<00:31, 25.89 examples/s]Converting format of dataset (num_proc=16):  20%|█▉        | 197/1000 [00:07<00:26, 29.93 examples/s]Converting format of dataset (num_proc=16):  20%|██        | 204/1000 [00:07<00:22, 34.86 examples/s]Converting format of dataset (num_proc=16):  21%|██        | 209/1000 [00:08<00:25, 31.50 examples/s]Converting format of dataset (num_proc=16):  21%|██▏       | 214/1000 [00:08<00:22, 34.32 examples/s]Converting format of dataset (num_proc=16):  22%|██▏       | 219/1000 [00:08<00:20, 37.70 examples/s]Converting format of dataset (num_proc=16):  22%|██▏       | 224/1000 [00:08<00:23, 33.02 examples/s]Converting format of dataset (num_proc=16):  23%|██▎       | 228/1000 [00:08<00:22, 34.41 examples/s]Converting format of dataset (num_proc=16):  23%|██▎       | 232/1000 [00:08<00:22, 34.79 examples/s]Converting format of dataset (num_proc=16):  24%|██▎       | 236/1000 [00:09<00:28, 26.72 examples/s]Converting format of dataset (num_proc=16):  24%|██▍       | 242/1000 [00:09<00:26, 28.78 examples/s]Converting format of dataset (num_proc=16):  25%|██▍       | 248/1000 [00:09<00:22, 33.06 examples/s]Converting format of dataset (num_proc=16):  25%|██▌       | 252/1000 [00:09<00:26, 28.37 examples/s]Converting format of dataset (num_proc=16):  26%|██▌       | 256/1000 [00:09<00:27, 27.04 examples/s]Converting format of dataset (num_proc=16):  26%|██▌       | 260/1000 [00:09<00:25, 28.82 examples/s]Converting format of dataset (num_proc=16):  26%|██▋       | 264/1000 [00:09<00:25, 28.83 examples/s]Converting format of dataset (num_proc=16):  27%|██▋       | 270/1000 [00:10<00:20, 35.34 examples/s]Converting format of dataset (num_proc=16):  28%|██▊       | 276/1000 [00:10<00:19, 37.80 examples/s]Converting format of dataset (num_proc=16):  28%|██▊       | 280/1000 [00:10<00:23, 30.22 examples/s]Converting format of dataset (num_proc=16):  29%|██▊       | 287/1000 [00:10<00:19, 35.76 examples/s]Converting format of dataset (num_proc=16):  29%|██▉       | 292/1000 [00:10<00:18, 37.50 examples/s]Converting format of dataset (num_proc=16):  30%|██▉       | 299/1000 [00:10<00:16, 42.36 examples/s]Converting format of dataset (num_proc=16):  30%|███       | 304/1000 [00:11<00:20, 34.73 examples/s]Converting format of dataset (num_proc=16):  31%|███       | 308/1000 [00:11<00:23, 29.46 examples/s]Converting format of dataset (num_proc=16):  31%|███       | 312/1000 [00:11<00:23, 29.47 examples/s]Converting format of dataset (num_proc=16):  32%|███▏      | 317/1000 [00:11<00:22, 30.75 examples/s]Converting format of dataset (num_proc=16):  32%|███▏      | 321/1000 [00:11<00:24, 27.70 examples/s]Converting format of dataset (num_proc=16):  33%|███▎      | 326/1000 [00:11<00:21, 31.57 examples/s]Converting format of dataset (num_proc=16):  33%|███▎      | 333/1000 [00:11<00:18, 35.80 examples/s]Converting format of dataset (num_proc=16):  34%|███▍      | 338/1000 [00:12<00:17, 36.94 examples/s]Converting format of dataset (num_proc=16):  34%|███▍      | 342/1000 [00:12<00:18, 34.92 examples/s]Converting format of dataset (num_proc=16):  35%|███▌      | 352/1000 [00:12<00:15, 42.46 examples/s]Converting format of dataset (num_proc=16):  36%|███▌      | 357/1000 [00:12<00:14, 44.00 examples/s]Converting format of dataset (num_proc=16):  36%|███▌      | 362/1000 [00:12<00:16, 39.01 examples/s]Converting format of dataset (num_proc=16):  37%|███▋      | 366/1000 [00:12<00:18, 34.24 examples/s]Converting format of dataset (num_proc=16):  37%|███▋      | 370/1000 [00:12<00:18, 33.38 examples/s]Converting format of dataset (num_proc=16):  37%|███▋      | 374/1000 [00:13<00:21, 28.96 examples/s]Converting format of dataset (num_proc=16):  38%|███▊      | 378/1000 [00:13<00:20, 29.82 examples/s]Converting format of dataset (num_proc=16):  38%|███▊      | 382/1000 [00:13<00:20, 29.95 examples/s]Converting format of dataset (num_proc=16):  39%|███▊      | 386/1000 [00:13<00:22, 26.81 examples/s]Converting format of dataset (num_proc=16):  39%|███▉      | 390/1000 [00:13<00:23, 25.57 examples/s]Converting format of dataset (num_proc=16):  39%|███▉      | 394/1000 [00:13<00:21, 28.46 examples/s]Converting format of dataset (num_proc=16):  40%|████      | 400/1000 [00:14<00:18, 32.14 examples/s]Converting format of dataset (num_proc=16):  40%|████      | 405/1000 [00:14<00:16, 35.49 examples/s]Converting format of dataset (num_proc=16):  41%|████      | 409/1000 [00:14<00:17, 34.70 examples/s]Converting format of dataset (num_proc=16):  42%|████▏     | 415/1000 [00:14<00:14, 39.68 examples/s]Converting format of dataset (num_proc=16):  42%|████▏     | 420/1000 [00:14<00:15, 38.16 examples/s]Converting format of dataset (num_proc=16):  42%|████▏     | 424/1000 [00:14<00:15, 36.29 examples/s]Converting format of dataset (num_proc=16):  43%|████▎     | 428/1000 [00:14<00:15, 36.81 examples/s]Converting format of dataset (num_proc=16):  44%|████▎     | 436/1000 [00:14<00:13, 41.23 examples/s]Converting format of dataset (num_proc=16):  44%|████▍     | 441/1000 [00:15<00:13, 40.84 examples/s]Converting format of dataset (num_proc=16):  45%|████▍     | 447/1000 [00:15<00:13, 41.41 examples/s]Converting format of dataset (num_proc=16):  46%|████▌     | 455/1000 [00:15<00:10, 50.67 examples/s]Converting format of dataset (num_proc=16):  46%|████▌     | 461/1000 [00:15<00:12, 44.23 examples/s]Converting format of dataset (num_proc=16):  47%|████▋     | 466/1000 [00:15<00:13, 41.06 examples/s]Converting format of dataset (num_proc=16):  47%|████▋     | 472/1000 [00:15<00:14, 37.33 examples/s]Converting format of dataset (num_proc=16):  48%|████▊     | 479/1000 [00:15<00:11, 44.18 examples/s]Converting format of dataset (num_proc=16):  48%|████▊     | 485/1000 [00:16<00:12, 42.66 examples/s]Converting format of dataset (num_proc=16):  49%|████▉     | 490/1000 [00:16<00:12, 42.35 examples/s]Converting format of dataset (num_proc=16):  50%|████▉     | 496/1000 [00:16<00:10, 46.51 examples/s]Converting format of dataset (num_proc=16):  50%|█████     | 502/1000 [00:16<00:11, 42.80 examples/s]Converting format of dataset (num_proc=16):  51%|█████     | 507/1000 [00:16<00:11, 44.43 examples/s]Converting format of dataset (num_proc=16):  51%|█████     | 512/1000 [00:16<00:12, 39.48 examples/s]Converting format of dataset (num_proc=16):  52%|█████▏    | 521/1000 [00:16<00:10, 44.29 examples/s]Converting format of dataset (num_proc=16):  53%|█████▎    | 526/1000 [00:17<00:12, 38.25 examples/s]Converting format of dataset (num_proc=16):  53%|█████▎    | 530/1000 [00:17<00:12, 36.49 examples/s]Converting format of dataset (num_proc=16):  54%|█████▎    | 535/1000 [00:17<00:12, 35.90 examples/s]Converting format of dataset (num_proc=16):  54%|█████▍    | 540/1000 [00:17<00:13, 35.38 examples/s]Converting format of dataset (num_proc=16):  54%|█████▍    | 544/1000 [00:17<00:16, 26.83 examples/s]Converting format of dataset (num_proc=16):  55%|█████▍    | 547/1000 [00:17<00:16, 26.99 examples/s]Converting format of dataset (num_proc=16):  56%|█████▌    | 555/1000 [00:17<00:11, 37.46 examples/s]Converting format of dataset (num_proc=16):  56%|█████▌    | 560/1000 [00:18<00:11, 38.00 examples/s]Converting format of dataset (num_proc=16):  57%|█████▋    | 566/1000 [00:18<00:10, 40.43 examples/s]Converting format of dataset (num_proc=16):  57%|█████▋    | 572/1000 [00:18<00:09, 44.90 examples/s]Converting format of dataset (num_proc=16):  58%|█████▊    | 579/1000 [00:18<00:09, 45.09 examples/s]Converting format of dataset (num_proc=16):  59%|█████▊    | 586/1000 [00:18<00:09, 43.18 examples/s]Converting format of dataset (num_proc=16):  59%|█████▉    | 592/1000 [00:18<00:08, 46.97 examples/s]Converting format of dataset (num_proc=16):  60%|█████▉    | 597/1000 [00:18<00:08, 46.28 examples/s]Converting format of dataset (num_proc=16):  60%|██████    | 603/1000 [00:18<00:08, 48.63 examples/s]Converting format of dataset (num_proc=16):  61%|██████    | 609/1000 [00:19<00:08, 44.07 examples/s]Converting format of dataset (num_proc=16):  61%|██████▏   | 614/1000 [00:19<00:11, 33.03 examples/s]Converting format of dataset (num_proc=16):  62%|██████▏   | 619/1000 [00:19<00:10, 36.37 examples/s]Converting format of dataset (num_proc=16):  62%|██████▏   | 624/1000 [00:19<00:10, 34.62 examples/s]Converting format of dataset (num_proc=16):  63%|██████▎   | 629/1000 [00:19<00:09, 37.47 examples/s]Converting format of dataset (num_proc=16):  64%|██████▎   | 635/1000 [00:19<00:09, 38.50 examples/s]Converting format of dataset (num_proc=16):  64%|██████▍   | 640/1000 [00:19<00:08, 40.34 examples/s]Converting format of dataset (num_proc=16):  65%|██████▍   | 648/1000 [00:20<00:07, 46.42 examples/s]Converting format of dataset (num_proc=16):  65%|██████▌   | 653/1000 [00:20<00:08, 40.97 examples/s]Converting format of dataset (num_proc=16):  66%|██████▌   | 661/1000 [00:20<00:07, 48.21 examples/s]Converting format of dataset (num_proc=16):  67%|██████▋   | 667/1000 [00:20<00:09, 36.52 examples/s]Converting format of dataset (num_proc=16):  67%|██████▋   | 673/1000 [00:20<00:08, 40.72 examples/s]Converting format of dataset (num_proc=16):  68%|██████▊   | 678/1000 [00:20<00:09, 35.41 examples/s]Converting format of dataset (num_proc=16):  68%|██████▊   | 683/1000 [00:21<00:08, 36.18 examples/s]Converting format of dataset (num_proc=16):  69%|██████▉   | 691/1000 [00:21<00:07, 39.77 examples/s]Converting format of dataset (num_proc=16):  70%|██████▉   | 698/1000 [00:21<00:06, 44.95 examples/s]Converting format of dataset (num_proc=16):  70%|███████   | 704/1000 [00:21<00:06, 46.84 examples/s]Converting format of dataset (num_proc=16):  71%|███████   | 709/1000 [00:21<00:06, 43.45 examples/s]Converting format of dataset (num_proc=16):  71%|███████▏  | 714/1000 [00:21<00:07, 39.84 examples/s]Converting format of dataset (num_proc=16):  72%|███████▏  | 720/1000 [00:21<00:06, 42.53 examples/s]Converting format of dataset (num_proc=16):  73%|███████▎  | 726/1000 [00:22<00:05, 46.46 examples/s]Converting format of dataset (num_proc=16):  73%|███████▎  | 731/1000 [00:22<00:07, 35.12 examples/s]Converting format of dataset (num_proc=16):  74%|███████▍  | 740/1000 [00:22<00:05, 44.58 examples/s]Converting format of dataset (num_proc=16):  75%|███████▌  | 750/1000 [00:22<00:04, 52.20 examples/s]Converting format of dataset (num_proc=16):  76%|███████▌  | 756/1000 [00:22<00:04, 50.24 examples/s]Converting format of dataset (num_proc=16):  76%|███████▋  | 765/1000 [00:22<00:03, 59.42 examples/s]Converting format of dataset (num_proc=16):  77%|███████▋  | 772/1000 [00:22<00:04, 55.86 examples/s]Converting format of dataset (num_proc=16):  78%|███████▊  | 779/1000 [00:23<00:04, 54.30 examples/s]Converting format of dataset (num_proc=16):  79%|███████▉  | 791/1000 [00:23<00:02, 69.78 examples/s]Converting format of dataset (num_proc=16):  80%|███████▉  | 799/1000 [00:23<00:03, 50.32 examples/s]Converting format of dataset (num_proc=16):  81%|████████  | 806/1000 [00:23<00:03, 49.24 examples/s]Converting format of dataset (num_proc=16):  81%|████████▏ | 813/1000 [00:23<00:04, 46.24 examples/s]Converting format of dataset (num_proc=16):  82%|████████▏ | 822/1000 [00:23<00:03, 54.10 examples/s]Converting format of dataset (num_proc=16):  83%|████████▎ | 831/1000 [00:23<00:02, 60.88 examples/s]Converting format of dataset (num_proc=16):  84%|████████▍ | 838/1000 [00:24<00:02, 61.02 examples/s]Converting format of dataset (num_proc=16):  84%|████████▍ | 845/1000 [00:24<00:02, 59.36 examples/s]Converting format of dataset (num_proc=16):  85%|████████▌ | 852/1000 [00:24<00:02, 54.66 examples/s]Converting format of dataset (num_proc=16):  86%|████████▌ | 858/1000 [00:24<00:02, 54.84 examples/s]Converting format of dataset (num_proc=16):  86%|████████▋ | 864/1000 [00:24<00:03, 45.06 examples/s]Converting format of dataset (num_proc=16):  87%|████████▋ | 872/1000 [00:24<00:02, 52.75 examples/s]Converting format of dataset (num_proc=16):  88%|████████▊ | 879/1000 [00:24<00:02, 54.25 examples/s]Converting format of dataset (num_proc=16):  88%|████████▊ | 885/1000 [00:25<00:02, 41.84 examples/s]Converting format of dataset (num_proc=16):  89%|████████▉ | 891/1000 [00:25<00:02, 39.02 examples/s]Converting format of dataset (num_proc=16):  90%|████████▉ | 896/1000 [00:25<00:02, 36.07 examples/s]Converting format of dataset (num_proc=16):  90%|█████████ | 901/1000 [00:25<00:02, 38.67 examples/s]Converting format of dataset (num_proc=16):  91%|█████████ | 906/1000 [00:25<00:02, 37.09 examples/s]Converting format of dataset (num_proc=16):  91%|█████████ | 910/1000 [00:25<00:02, 33.25 examples/s]Converting format of dataset (num_proc=16):  92%|█████████▏| 918/1000 [00:25<00:01, 42.53 examples/s]Converting format of dataset (num_proc=16):  92%|█████████▏| 923/1000 [00:26<00:01, 42.08 examples/s]Converting format of dataset (num_proc=16):  93%|█████████▎| 928/1000 [00:26<00:01, 40.11 examples/s]Converting format of dataset (num_proc=16):  93%|█████████▎| 934/1000 [00:26<00:01, 39.82 examples/s]Converting format of dataset (num_proc=16):  94%|█████████▍| 942/1000 [00:26<00:01, 48.23 examples/s]Converting format of dataset (num_proc=16):  95%|█████████▍| 948/1000 [00:26<00:01, 40.07 examples/s]Converting format of dataset (num_proc=16):  95%|█████████▌| 953/1000 [00:26<00:01, 35.37 examples/s]Converting format of dataset (num_proc=16):  96%|█████████▌| 958/1000 [00:27<00:01, 37.26 examples/s]Converting format of dataset (num_proc=16):  96%|█████████▋| 963/1000 [00:27<00:01, 28.88 examples/s]Converting format of dataset (num_proc=16):  97%|█████████▋| 967/1000 [00:27<00:01, 26.15 examples/s]Converting format of dataset (num_proc=16):  97%|█████████▋| 970/1000 [00:27<00:01, 24.13 examples/s]Converting format of dataset (num_proc=16):  97%|█████████▋| 973/1000 [00:27<00:01, 24.24 examples/s]Converting format of dataset (num_proc=16):  98%|█████████▊| 978/1000 [00:27<00:00, 25.60 examples/s]Converting format of dataset (num_proc=16):  98%|█████████▊| 981/1000 [00:28<00:00, 24.34 examples/s]Converting format of dataset (num_proc=16):  98%|█████████▊| 984/1000 [00:28<00:00, 18.71 examples/s]Converting format of dataset (num_proc=16):  99%|█████████▉| 989/1000 [00:28<00:00, 19.80 examples/s]Converting format of dataset (num_proc=16):  99%|█████████▉| 994/1000 [00:28<00:00, 20.99 examples/s]Converting format of dataset (num_proc=16): 100%|█████████▉| 998/1000 [00:28<00:00, 21.13 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 1000/1000 [00:29<00:00, 34.08 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:01<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:02<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:02<?, ? examples/s]
multiprocess.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 586, in _write_generator_to_queue
    for i, result in enumerate(func(**kwargs)):
  File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3674, in _map_single
    for i, batch in iter_outputs(shard_iterable):
  File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3624, in iter_outputs
    yield i, apply_function(example, i, offset=offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3547, in apply_function
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/data/processor/supervised.py", line 99, in preprocess_dataset
    input_ids, labels = self._encode_data_example(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/data/processor/supervised.py", line 43, in _encode_data_example
    messages = self.template.mm_plugin.process_messages(prompt + response, images, videos, audios, self.processor)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/data/mm_plugin.py", line 1499, in process_messages
    self._validate_messages(messages, images, videos, audios)
  File "/app/src/llamafactory/data/mm_plugin.py", line 202, in _validate_messages
    raise ValueError(
ValueError: The number of images does not match the number of <image> tokens in [{'content': "What is on top of the bathroom cabinet that is on my 11 o'clock?", 'role': 'user'}, {'content': '\nGot it, let\'s try to figure out what\'s on top of the bathroom cabinet at 11 o\'clock. First, let\'s visualize the bathroom setup. The cabinet is likely a white, two-drawer unit. At 11 o\'clock (top-left area), we need to check that spot. Looking at the images, especially the one showing the cabinet area, there\'s a mirror above the sink, but wait, no—wait, the question is about the cabinet. Wait, maybe the "cabinet" here is the storage unit. Wait, no, the sink has a cabinet below? Wait, no, the main cabinet is the white drawers. Wait, in the image where the camera shows the sink and cabinet, the top of the cabinet—wait, no, maybe the mirror? Wait, no, let\'s check again. Wait, the user says "bathroom cabinet that is on my 11 o\'clock". So 11 o\'clock would be the upper left area relative to the sink. Looking at the images, there\'s a mirror mounted on the wall above the sink area. Is that part of the cabinet setup? Wait, no, maybe the cabinet is the white drawers under the sink. Wait, no, the top of that cabinet—wait, no, in some images, there\'s a mirror reflected or mounted. Wait, no, let\'s check the first few images. The shower curtain is colorful, then the sink area. Wait, the correct answer: looking at the images, the object on top of the bathroom cabinet (the white drawer unit) at 11 o\'clock is a mirror. Wait, no, wait—the mirror is on the wall above the sink. Wait, maybe I misread. Wait, no, let\'s check again. Wait, the user\'s question: "What is on top of the bathroom cabinet that is on my 11 o\'clock?" So first, identify the cabinet. The white drawer unit near 11 o\'clock (top-left). What\'s on top? Looking at the images, there\'s a mirror mounted on the wall above that area. Wait, yes! In the reflection or mounted, there\'s a mirror. So the answer is a mirror.\n\n\nTo determine what is on top of the bathroom cabinet at 11 o’clock, analyze the spatial layout and elements in the images:  \n\n1. Locate the “bathroom cabinet” in question: A white, two - drawer storage unit is visible near the top - left (11 o’clock) area relative to other fixtures like the sink and shower.  \n2. Examine objects above this cabinet: In the images, a **mirror** is mounted on the wall above this cabinet area.  \n\n\nMirror', 'role': 'assistant'}].
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/app/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/app/src/llamafactory/launcher.py", line 152, in launch
    run_exp()
  File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
    _training_function(config={"args": args, "callbacks": callbacks})
  File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
  File "/app/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
    dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/data/loader.py", line 315, in get_dataset
    dataset = _get_preprocessed_dataset(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/data/loader.py", line 256, in _get_preprocessed_dataset
    dataset = dataset.map(
              ^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3309, in map
    for rank, done, content in iflatmap_unordered(
  File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 626, in iflatmap_unordered
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/opt/conda/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 626, in <listcomp>
    [async_result.get(timeout=0.05) for async_result in async_results]
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/multiprocess/pool.py", line 774, in get
    raise self._value
ValueError: The number of images does not match the number of <image> tokens in [{'content': "What is on top of the bathroom cabinet that is on my 11 o'clock?", 'role': 'user'}, {'content': '\nGot it, let\'s try to figure out what\'s on top of the bathroom cabinet at 11 o\'clock. First, let\'s visualize the bathroom setup. The cabinet is likely a white, two-drawer unit. At 11 o\'clock (top-left area), we need to check that spot. Looking at the images, especially the one showing the cabinet area, there\'s a mirror above the sink, but wait, no—wait, the question is about the cabinet. Wait, maybe the "cabinet" here is the storage unit. Wait, no, the sink has a cabinet below? Wait, no, the main cabinet is the white drawers. Wait, in the image where the camera shows the sink and cabinet, the top of the cabinet—wait, no, maybe the mirror? Wait, no, let\'s check again. Wait, the user says "bathroom cabinet that is on my 11 o\'clock". So 11 o\'clock would be the upper left area relative to the sink. Looking at the images, there\'s a mirror mounted on the wall above the sink area. Is that part of the cabinet setup? Wait, no, maybe the cabinet is the white drawers under the sink. Wait, no, the top of that cabinet—wait, no, in some images, there\'s a mirror reflected or mounted. Wait, no, let\'s check the first few images. The shower curtain is colorful, then the sink area. Wait, the correct answer: looking at the images, the object on top of the bathroom cabinet (the white drawer unit) at 11 o\'clock is a mirror. Wait, no, wait—the mirror is on the wall above the sink. Wait, maybe I misread. Wait, no, let\'s check again. Wait, the user\'s question: "What is on top of the bathroom cabinet that is on my 11 o\'clock?" So first, identify the cabinet. The white drawer unit near 11 o\'clock (top-left). What\'s on top? Looking at the images, there\'s a mirror mounted on the wall above that area. Wait, yes! In the reflection or mounted, there\'s a mirror. So the answer is a mirror.\n\n\nTo determine what is on top of the bathroom cabinet at 11 o’clock, analyze the spatial layout and elements in the images:  \n\n1. Locate the “bathroom cabinet” in question: A white, two - drawer storage unit is visible near the top - left (11 o’clock) area relative to other fixtures like the sink and shower.  \n2. Examine objects above this cabinet: In the images, a **mirror** is mounted on the wall above this cabinet area.  \n\n\nMirror', 'role': 'assistant'}].
INFO:    Cleanup error: while stopping driver for /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/apptainer/1.3.5/var/apptainer/mnt/session/final: fuse-overlayfs exited: fuse: reading device: Software caused connection abort

scontrol show job 85846
JobId=85846 JobName=slurm_qwen2_5vl_lora_sft_SQA3D.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=329658 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:59 TimeLimit=00:25:00 TimeMin=N/A
   SubmitTime=2025-11-13T01:06:19 EligibleTime=2025-11-13T01:06:19
   AccrueTime=2025-11-13T01:06:19
   StartTime=2025-11-13T01:14:00 EndTime=2025-11-13T01:14:59 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-13T01:14:00 Scheduler=Backfill
   Partition=compute AllocNode:Sid=trig-login01:731173
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0060
   BatchHost=trig0060
   NumNodes=1 NumCPUs=4 NumTasks=1 CPUs/Task=4 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=4,mem=192500M,node=1,billing=1,gres/gpu=1
   AllocTRES=cpu=4,mem=192500M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=4 MinMemoryNode=192500M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=./slurm_qwen2_5vl_lora_sft_SQA3D.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L ./slurm_qwen2_5vl_lora_sft_SQA3D.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85846.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85846.out
   TresPerNode=gres/gpu:h100:1
   TresPerTask=cpu=4
   

sacct -j 85846
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
85846        slurm_qwe+ def-wangcs   00:00:59                         00:00:00   00:00:00      0:0 
85846.batch       batch def-wangcs   00:00:59                         00:00:00   00:00:00      0:0 
85846.extern     extern def-wangcs   00:00:59                         00:00:00   00:00:00      0:0 

