WARNING: Skipping /dev/shm bind mount: already mounted

==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[INFO|2025-12-21 04:43:16] llamafactory.launcher:143 >> Initializing 4 distributed tasks at: 127.0.0.1:59921
W1221 04:43:17.734000 165 site-packages/torch/distributed/run.py:792] 
W1221 04:43:17.734000 165 site-packages/torch/distributed/run.py:792] *****************************************
W1221 04:43:17.734000 165 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1221 04:43:17.734000 165 site-packages/torch/distributed/run.py:792] *****************************************
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
[2025-12-21 04:43:27,400] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-21 04:43:27,400] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-21 04:43:27,401] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-21 04:43:27,401] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[2025-12-21 04:43:31,779] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-12-21 04:43:31,779] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-12-21 04:43:31,787] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-12-21 04:43:31,808] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-12-21 04:43:31,808] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[INFO|2025-12-21 04:43:32] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-12-21 04:43:32] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|hub.py:421] 2025-12-21 04:43:32,247 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2025-12-21 04:43:32,258 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file added_tokens.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/added_tokens.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file special_tokens_map.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/special_tokens_map.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,263 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-12-21 04:43:32,581 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2025-12-21 04:43:32,582 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2025-12-21 04:43:32,583 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2025-12-21 04:43:32,584 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-12-21 04:43:32,585 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/preprocessor_config.json
[INFO|image_processing_base.py:316] 2025-12-21 04:43:32,588 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-12-21 04:43:32,589 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-12-21 04:43:32,598 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 401408,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 401408,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2025-12-21 04:43:32,598 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,599 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,599 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,599 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,600 >> loading file added_tokens.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/added_tokens.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,600 >> loading file special_tokens_map.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/special_tokens_map.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,600 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-12-21 04:43:32,600 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-12-21 04:43:32,867 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2025-12-21 04:43:32,868 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2025-12-21 04:43:32,870 >> loading configuration file video_preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Video-R1--Video-R1-7B/snapshots/e6840e4cdc86b484b05aacdcb5c88ad3d7ef3d76/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-12-21 04:43:32,874 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 401408,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 401408,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-12-21 04:43:32,874 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2025-12-21 04:43:32,877 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2025-12-21 04:43:33,201 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 401408,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 401408,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Video-R1/Video-R1-7B', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 401408,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 401408,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

[rank0]: Traceback (most recent call last):
[rank0]:   File "/app/src/llamafactory/launcher.py", line 180, in <module>
[rank0]:     run_exp()
[rank0]:   File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank0]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank0]:   File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank0]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank0]:   File "/app/src/llamafactory/train/sft/workflow.py", line 50, in run_sft
[rank0]:     template = get_template_and_fix_tokenizer(tokenizer, data_args)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/app/src/llamafactory/data/template.py", line 602, in get_template_and_fix_tokenizer
[rank0]:     raise ValueError(f"Template {data_args.template} does not exist.")
[rank0]: ValueError: Template videor1 does not exist.
[rank0]:[W1221 04:43:33.507377533 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[INFO|2025-12-21 04:43:33] llamafactory.hparams.parser:423 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-12-21 04:43:34] llamafactory.hparams.parser:423 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-12-21 04:43:34] llamafactory.hparams.parser:423 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[rank1]: Traceback (most recent call last):
[rank1]:   File "/app/src/llamafactory/launcher.py", line 180, in <module>
[rank1]:     run_exp()
[rank1]:   File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank1]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank1]:   File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank1]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank1]:   File "/app/src/llamafactory/train/sft/workflow.py", line 50, in run_sft
[rank1]:     template = get_template_and_fix_tokenizer(tokenizer, data_args)
[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/app/src/llamafactory/data/template.py", line 602, in get_template_and_fix_tokenizer
[rank1]:     raise ValueError(f"Template {data_args.template} does not exist.")
[rank1]: ValueError: Template videor1 does not exist.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/app/src/llamafactory/launcher.py", line 180, in <module>
[rank3]:     run_exp()
[rank3]:   File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank3]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank3]:   File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank3]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank3]:   File "/app/src/llamafactory/train/sft/workflow.py", line 50, in run_sft
[rank3]:     template = get_template_and_fix_tokenizer(tokenizer, data_args)
[rank3]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/app/src/llamafactory/data/template.py", line 602, in get_template_and_fix_tokenizer
[rank3]:     raise ValueError(f"Template {data_args.template} does not exist.")
[rank3]: ValueError: Template videor1 does not exist.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/app/src/llamafactory/launcher.py", line 180, in <module>
[rank2]:     run_exp()
[rank2]:   File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank2]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank2]:   File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank2]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank2]:   File "/app/src/llamafactory/train/sft/workflow.py", line 50, in run_sft
[rank2]:     template = get_template_and_fix_tokenizer(tokenizer, data_args)
[rank2]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/app/src/llamafactory/data/template.py", line 602, in get_template_and_fix_tokenizer
[rank2]:     raise ValueError(f"Template {data_args.template} does not exist.")
[rank2]: ValueError: Template videor1 does not exist.
W1221 04:43:35.466000 165 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 231 closing signal SIGTERM
W1221 04:43:35.466000 165 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 232 closing signal SIGTERM
W1221 04:43:35.466000 165 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 233 closing signal SIGTERM
E1221 04:43:35.796000 165 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 230) of binary: /opt/conda/bin/python3.11
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/app/src/llamafactory/launcher.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-12-21_04:43:35
  host      : rg32403.rorqual.calcul.quebec
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 230)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/app/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/app/src/llamafactory/launcher.py", line 110, in launch
    process = subprocess.run(
              ^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['torchrun', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '4', '--master_addr', '127.0.0.1', '--master_port', '59921', '/app/src/llamafactory/launcher.py', '/scratch/indrisch/LLaMA-Factory/examples/train_lora/videor1_lora_sft_SQA3Devery24_traineval.yaml']' returned non-zero exit status 1.
