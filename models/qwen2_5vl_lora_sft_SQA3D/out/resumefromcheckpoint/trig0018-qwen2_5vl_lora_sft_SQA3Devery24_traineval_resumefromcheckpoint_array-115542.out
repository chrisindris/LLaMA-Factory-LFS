Task number: 5
Most Recent Save: 465
New Epoch: 244
New YAML: /scratch/indrisch//LLaMA-Factory/examples/train_lora//qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_5.yaml
python: can't open file '/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/modify_yaml.py': [Errno 2] No such file or directory
./multi_runner.sh: line 63: num_train_epochs: command not found
WARNING: Environment variable TORCH_EXTENSIONS_DIR already has value [/dev/shm/slurm.indrisch.115542/.cache/torch_extensions], will not forward new value [None] from parent process environment
WARNING: Environment variable PYTORCH_KERNEL_CACHE_PATH already has value [/dev/shm/slurm.indrisch.115542/.cache/torch/kernels], will not forward new value [None] from parent process environment
WARNING: Environment variable FORCE_TORCHRUN already has value [1], will not forward new value [None] from parent process environment

==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[INFO|2025-11-30 06:31:21] llamafactory.launcher:143 >> Initializing 4 distributed tasks at: 127.0.0.1:35265
W1130 06:31:22.612000 1797102 site-packages/torch/distributed/run.py:792] 
W1130 06:31:22.612000 1797102 site-packages/torch/distributed/run.py:792] *****************************************
W1130 06:31:22.612000 1797102 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1130 06:31:22.612000 1797102 site-packages/torch/distributed/run.py:792] *****************************************
[2025-11-30 06:31:29,016] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /scratch/indrisch/.triton_cache, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2025-11-30 06:31:29,535] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-30 06:31:29,566] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-30 06:31:29,572] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /scratch/indrisch/.triton_cache, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /scratch/indrisch/.triton_cache, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /scratch/indrisch/.triton_cache, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 180, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py", line 47, in <module>
    from .utils import (
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/utils.py", line 51, in <module>
    import deepspeed
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
    from ..git_version_info import compatible_ops as __compatible_ops__
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/git_version_info.py", line 29, in <module>
    op_compatible = builder.is_compatible()
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
    sys_cuda_major, _ = installed_cuda_version()
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 53, in installed_cuda_version
    output = subprocess.check_output([cuda_home + "/bin/nvcc", "-V"], universal_newlines=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 466, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 548, in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 1026, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/opt/conda/lib/python3.11/subprocess.py", line 1955, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/llamafactory/launcher.py", line 178, in <module>
    from llamafactory.train.tuner import run_exp  # use absolute import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/train/tuner.py", line 31, in <module>
    from .dpo import run_dpo
  File "/app/src/llamafactory/train/dpo/__init__.py", line 15, in <module>
    from .workflow import run_dpo
  File "/app/src/llamafactory/train/dpo/workflow.py", line 27, in <module>
    from .trainer import CustomDPOTrainer
  File "/app/src/llamafactory/train/dpo/trainer.py", line 27, in <module>
    from trl import DPOTrainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 171, in __getattr__
    value = getattr(module, name)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 170, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 182, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import trl.trainer.dpo_trainer because of the following error (look up to see its traceback):
[Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 180, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py", line 47, in <module>
    from .utils import (
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/utils.py", line 51, in <module>
    import deepspeed
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
    from ..git_version_info import compatible_ops as __compatible_ops__
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/git_version_info.py", line 29, in <module>
    op_compatible = builder.is_compatible()
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
    sys_cuda_major, _ = installed_cuda_version()
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 53, in installed_cuda_version
    output = subprocess.check_output([cuda_home + "/bin/nvcc", "-V"], universal_newlines=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 466, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 548, in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 1026, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/opt/conda/lib/python3.11/subprocess.py", line 1955, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/llamafactory/launcher.py", line 178, in <module>
    from llamafactory.train.tuner import run_exp  # use absolute import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/train/tuner.py", line 31, in <module>
    from .dpo import run_dpo
  File "/app/src/llamafactory/train/dpo/__init__.py", line 15, in <module>
    from .workflow import run_dpo
  File "/app/src/llamafactory/train/dpo/workflow.py", line 27, in <module>
    from .trainer import CustomDPOTrainer
  File "/app/src/llamafactory/train/dpo/trainer.py", line 27, in <module>
    from trl import DPOTrainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 171, in __getattr__
    value = getattr(module, name)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 170, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 182, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import trl.trainer.dpo_trainer because of the following error (look up to see its traceback):
[Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 180, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py", line 47, in <module>
    from .utils import (
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/utils.py", line 51, in <module>
    import deepspeed
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
    from ..git_version_info import compatible_ops as __compatible_ops__
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/git_version_info.py", line 29, in <module>
    op_compatible = builder.is_compatible()
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
    sys_cuda_major, _ = installed_cuda_version()
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 53, in installed_cuda_version
    output = subprocess.check_output([cuda_home + "/bin/nvcc", "-V"], universal_newlines=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 466, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 548, in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 1026, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/opt/conda/lib/python3.11/subprocess.py", line 1955, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/llamafactory/launcher.py", line 178, in <module>
    from llamafactory.train.tuner import run_exp  # use absolute import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/train/tuner.py", line 31, in <module>
    from .dpo import run_dpo
  File "/app/src/llamafactory/train/dpo/__init__.py", line 15, in <module>
    from .workflow import run_dpo
  File "/app/src/llamafactory/train/dpo/workflow.py", line 27, in <module>
    from .trainer import CustomDPOTrainer
  File "/app/src/llamafactory/train/dpo/trainer.py", line 27, in <module>
    from trl import DPOTrainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 171, in __getattr__
    value = getattr(module, name)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 170, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 182, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import trl.trainer.dpo_trainer because of the following error (look up to see its traceback):
[Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 180, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py", line 47, in <module>
    from .utils import (
  File "/opt/conda/lib/python3.11/site-packages/trl/trainer/utils.py", line 51, in <module>
    import deepspeed
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
    from ..git_version_info import compatible_ops as __compatible_ops__
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/git_version_info.py", line 29, in <module>
    op_compatible = builder.is_compatible()
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
    sys_cuda_major, _ = installed_cuda_version()
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py", line 53, in installed_cuda_version
    output = subprocess.check_output([cuda_home + "/bin/nvcc", "-V"], universal_newlines=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 466, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 548, in run
    with Popen(*popenargs, **kwargs) as process:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 1026, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/opt/conda/lib/python3.11/subprocess.py", line 1955, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/llamafactory/launcher.py", line 178, in <module>
    from llamafactory.train.tuner import run_exp  # use absolute import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/train/tuner.py", line 31, in <module>
    from .dpo import run_dpo
  File "/app/src/llamafactory/train/dpo/__init__.py", line 15, in <module>
    from .workflow import run_dpo
  File "/app/src/llamafactory/train/dpo/workflow.py", line 27, in <module>
    from .trainer import CustomDPOTrainer
  File "/app/src/llamafactory/train/dpo/trainer.py", line 27, in <module>
    from trl import DPOTrainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 171, in __getattr__
    value = getattr(module, name)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 170, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/trl/import_utils.py", line 182, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import trl.trainer.dpo_trainer because of the following error (look up to see its traceback):
[Errno 2] No such file or directory: '/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Core/cudacore/12.6.2/bin/nvcc'
W1130 06:31:30.833000 1797102 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1797167 closing signal SIGTERM
W1130 06:31:30.833000 1797102 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1797168 closing signal SIGTERM
W1130 06:31:30.834000 1797102 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1797169 closing signal SIGTERM
E1130 06:31:30.948000 1797102 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 1797170) of binary: /opt/conda/bin/python3.11
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/app/src/llamafactory/launcher.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-30_06:31:30
  host      : trig0018.scinet.local
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 1797170)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/app/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/app/src/llamafactory/launcher.py", line 110, in launch
    process = subprocess.run(
              ^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['torchrun', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '4', '--master_addr', '127.0.0.1', '--master_port', '35265', '/app/src/llamafactory/launcher.py', '/scratch/indrisch//LLaMA-Factory/examples/train_lora//qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_5.yaml']' returned non-zero exit status 1.

scontrol show job 115542
JobId=115542 ArrayJobId=115542 ArrayTaskId=5 JobName=array_job.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=139448 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:29 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2025-11-30T06:23:26 EligibleTime=2025-11-30T06:23:26
   AccrueTime=2025-11-30T06:23:26
   StartTime=2025-11-30T06:31:03 EndTime=2025-11-30T06:31:32 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-30T06:31:03 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:3018829
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0018
   BatchHost=trig0018
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/array_job.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L array_job.sh TRILLIUM 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115542.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115542.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

JobId=115550 ArrayJobId=115542 ArrayTaskId=4 JobName=array_job.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=139448 Nice=0 Account=def-wangcs QOS=normal
   JobState=FAILED Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:29 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2025-11-30T06:23:26 EligibleTime=2025-11-30T06:23:26
   AccrueTime=2025-11-30T06:23:26
   StartTime=2025-11-30T06:30:33 EndTime=2025-11-30T06:31:02 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-30T06:30:33 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:3018829
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0018
   BatchHost=trig0018
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/array_job.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L array_job.sh TRILLIUM 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115550.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115550.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

JobId=115549 ArrayJobId=115542 ArrayTaskId=3 JobName=array_job.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=139442 Nice=0 Account=def-wangcs QOS=normal
   JobState=FAILED Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:30 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2025-11-30T06:23:26 EligibleTime=2025-11-30T06:23:26
   AccrueTime=2025-11-30T06:23:26
   StartTime=2025-11-30T06:30:02 EndTime=2025-11-30T06:30:32 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-30T06:30:02 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:3018829
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0018
   BatchHost=trig0018
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/array_job.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L array_job.sh TRILLIUM 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115549.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115549.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

JobId=115548 ArrayJobId=115542 ArrayTaskId=2 JobName=array_job.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=139442 Nice=0 Account=def-wangcs QOS=normal
   JobState=FAILED Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:30 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2025-11-30T06:23:26 EligibleTime=2025-11-30T06:23:26
   AccrueTime=2025-11-30T06:23:26
   StartTime=2025-11-30T06:29:31 EndTime=2025-11-30T06:30:01 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-30T06:29:31 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:3018829
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0018
   BatchHost=trig0018
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/array_job.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L array_job.sh TRILLIUM 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115548.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115548.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

JobId=115546 ArrayJobId=115542 ArrayTaskId=1 JobName=array_job.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=139442 Nice=0 Account=def-wangcs QOS=normal
   JobState=FAILED Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:37 TimeLimit=00:15:00 TimeMin=N/A
   SubmitTime=2025-11-30T06:23:26 EligibleTime=2025-11-30T06:23:26
   AccrueTime=2025-11-30T06:23:26
   StartTime=2025-11-30T06:28:54 EndTime=2025-11-30T06:29:31 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-30T06:28:54 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:3018829
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0018
   BatchHost=trig0018
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/array_job.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L array_job.sh TRILLIUM 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115546.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3Devery24_traineval_resumefromcheckpoint_array-115546.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

sacct -j 115542
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
115542_1     array_job+ def-wangcs   00:00:37                        00:27.541  00:34.133      1:0 
115542_1.ba+      batch def-wangcs   00:00:37          0   4714924K  00:27.540  00:34.132      1:0 
115542_1.ex+     extern def-wangcs   00:00:37          0        64K   00:00:00   00:00:00      0:0 
115542_2     array_job+ def-wangcs   00:00:30                        00:28.227  00:34.245      1:0 
115542_2.ba+      batch def-wangcs   00:00:30          0     15072K  00:28.225  00:34.245      1:0 
115542_2.ex+     extern def-wangcs   00:00:30          0        44K  00:00.001   00:00:00      0:0 
115542_3     array_job+ def-wangcs   00:00:30                        00:28.338  00:34.775      1:0 
115542_3.ba+      batch def-wangcs   00:00:30          0     15240K  00:28.337  00:34.775      1:0 
115542_3.ex+     extern def-wangcs   00:00:30          0        24K  00:00.001   00:00:00      0:0 
115542_4     array_job+ def-wangcs   00:00:29                        00:28.135  00:34.718      1:0 
115542_4.ba+      batch def-wangcs   00:00:29          0     14480K  00:28.133  00:34.718      1:0 
115542_4.ex+     extern def-wangcs   00:00:29          0        48K  00:00.001   00:00:00      0:0 
115542_5     array_job+ def-wangcs   00:00:29                         00:00:00   00:00:00      0:0 
115542_5.ba+      batch def-wangcs   00:00:29                         00:00:00   00:00:00      0:0 
115542_5.ex+     extern def-wangcs   00:00:29                         00:00:00   00:00:00      0:0 

