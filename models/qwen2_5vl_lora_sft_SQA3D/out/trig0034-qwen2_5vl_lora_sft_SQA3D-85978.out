
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[INFO|2025-11-13 07:26:32] llamafactory.launcher:143 >> Initializing 4 distributed tasks at: 127.0.0.1:58411
W1113 07:26:33.639000 223313 site-packages/torch/distributed/run.py:792] 
W1113 07:26:33.639000 223313 site-packages/torch/distributed/run.py:792] *****************************************
W1113 07:26:33.639000 223313 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1113 07:26:33.639000 223313 site-packages/torch/distributed/run.py:792] *****************************************
[2025-11-13 07:26:41,522] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-13 07:26:41,535] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-13 07:26:41,752] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-13 07:26:41,963] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[2025-11-13 07:26:44,772] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-11-13 07:26:44,772] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-11-13 07:26:44,772] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-11-13 07:26:44,772] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-11-13 07:26:44,773] [INFO] [comm.py:669:init_distributed] cdb=None
[INFO|2025-11-13 07:26:45] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-11-13 07:26:45] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|hub.py:421] 2025-11-13 07:26:45,136 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2025-11-13 07:26:45,153 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,164 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-13 07:26:45,381 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2025-11-13 07:26:45,381 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2025-11-13 07:26:45,382 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2025-11-13 07:26:45,385 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-13 07:26:45,387 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:316] 2025-11-13 07:26:45,391 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-13 07:26:45,392 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-11-13 07:26:45,401 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2025-11-13 07:26:45,401 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-13 07:26:45,406 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-13 07:26:45,614 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2025-11-13 07:26:45,616 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2025-11-13 07:26:45,618 >> loading configuration file video_preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-11-13 07:26:45,622 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-11-13 07:26:45,622 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2025-11-13 07:26:45,627 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2025-11-13 07:26:45,938 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

[INFO|2025-11-13 07:26:45] llamafactory.data.loader:143 >> Loading dataset /scratch/indrisch/huggingface/hub/datasets--cvis-tmu--llamafactory-sqa3d-traces-multiimage-vqa/snapshots/942a5514a2ed64b8ad7ec624ecde74f08884f1c8/data/...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
[INFO|2025-11-13 07:26:46] llamafactory.hparams.parser:423 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-11-13 07:26:46] llamafactory.hparams.parser:423 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-11-13 07:26:46] llamafactory.hparams.parser:423 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
Converting format of dataset (num_proc=96):   0%|          | 0/33047 [00:00<?, ? examples/s][rank3]:[W1113 07:26:47.127694103 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W1113 07:26:47.128043183 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W1113 07:26:47.137737573 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Converting format of dataset (num_proc=96):   0%|          | 1/33047 [00:01<13:46:22,  1.50s/ examples]Converting format of dataset (num_proc=96):   0%|          | 7/33047 [00:01<1:35:18,  5.78 examples/s] Converting format of dataset (num_proc=96):   0%|          | 17/33047 [00:01<34:29, 15.96 examples/s] Converting format of dataset (num_proc=96):   0%|          | 37/33047 [00:01<13:39, 40.30 examples/s]Converting format of dataset (num_proc=96):   0%|          | 48/33047 [00:01<11:31, 47.75 examples/s]Converting format of dataset (num_proc=96):   0%|          | 62/33047 [00:02<08:41, 63.22 examples/s]Converting format of dataset (num_proc=96):   0%|          | 82/33047 [00:02<06:16, 87.66 examples/s]Converting format of dataset (num_proc=96):   0%|          | 95/33047 [00:02<05:53, 93.24 examples/s]Converting format of dataset (num_proc=96):   0%|          | 114/33047 [00:02<04:50, 113.37 examples/s]Converting format of dataset (num_proc=96):   0%|          | 132/33047 [00:02<04:17, 128.03 examples/s]Converting format of dataset (num_proc=96):   0%|          | 147/33047 [00:02<05:02, 108.73 examples/s]Converting format of dataset (num_proc=96):   1%|          | 170/33047 [00:02<04:11, 130.47 examples/s]Converting format of dataset (num_proc=96):   1%|          | 185/33047 [00:02<04:18, 127.30 examples/s]Converting format of dataset (num_proc=96):   1%|          | 205/33047 [00:03<03:52, 141.00 examples/s]Converting format of dataset (num_proc=96):   1%|          | 221/33047 [00:03<03:48, 143.85 examples/s]Converting format of dataset (num_proc=96):   1%|          | 238/33047 [00:03<03:52, 141.02 examples/s]Converting format of dataset (num_proc=96):   1%|          | 266/33047 [00:03<03:09, 173.20 examples/s]Converting format of dataset (num_proc=96):   1%|          | 284/33047 [00:03<03:12, 170.23 examples/s]Converting format of dataset (num_proc=96):   1%|          | 302/33047 [00:03<03:38, 150.15 examples/s]Converting format of dataset (num_proc=96):   1%|          | 320/33047 [00:03<03:50, 142.02 examples/s]Converting format of dataset (num_proc=96):   1%|          | 345/33047 [00:03<03:15, 167.24 examples/s]Converting format of dataset (num_proc=96):   1%|          | 370/33047 [00:04<02:54, 187.07 examples/s]Converting format of dataset (num_proc=96):   1%|          | 402/33047 [00:04<02:34, 210.94 examples/s]Converting format of dataset (num_proc=96):   1%|▏         | 431/33047 [00:04<02:21, 231.24 examples/s]Converting format of dataset (num_proc=96):   1%|▏         | 455/33047 [00:04<02:44, 198.04 examples/s]Converting format of dataset (num_proc=96):   1%|▏         | 477/33047 [00:04<02:43, 199.36 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 498/33047 [00:04<02:51, 190.12 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 526/33047 [00:04<02:35, 209.70 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 553/33047 [00:04<02:24, 225.55 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 585/33047 [00:04<02:12, 245.49 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 618/33047 [00:05<02:03, 263.53 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 645/33047 [00:05<02:06, 256.15 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 671/33047 [00:05<02:16, 237.32 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 711/33047 [00:05<02:00, 269.45 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 747/33047 [00:05<01:52, 286.08 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 776/33047 [00:05<01:59, 269.67 examples/s]Converting format of dataset (num_proc=96):   2%|▏         | 814/33047 [00:05<01:47, 298.56 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 846/33047 [00:05<01:58, 272.31 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 876/33047 [00:06<01:56, 276.95 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 906/33047 [00:06<01:55, 278.87 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 936/33047 [00:06<02:08, 249.49 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 962/33047 [00:06<02:24, 221.50 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 1003/33047 [00:06<02:06, 253.73 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 1030/33047 [00:06<02:06, 253.94 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 1058/33047 [00:06<02:05, 254.45 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 1103/33047 [00:06<01:47, 296.02 examples/s]Converting format of dataset (num_proc=96):   3%|▎         | 1135/33047 [00:07<01:54, 279.11 examples/s]Converting format of dataset (num_proc=96):   4%|▎         | 1178/33047 [00:07<01:41, 315.38 examples/s]Converting format of dataset (num_proc=96):   4%|▎         | 1228/33047 [00:07<01:27, 361.84 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1267/33047 [00:07<01:28, 358.69 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1305/33047 [00:07<01:34, 335.88 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1340/33047 [00:07<01:35, 332.07 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1374/33047 [00:07<01:47, 293.40 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1428/33047 [00:07<01:29, 352.16 examples/s]Converting format of dataset (num_proc=96):   4%|▍         | 1465/33047 [00:07<01:31, 344.04 examples/s]Converting format of dataset (num_proc=96):   5%|▍         | 1501/33047 [00:08<01:39, 316.37 examples/s]Converting format of dataset (num_proc=96):   5%|▍         | 1536/33047 [00:08<01:37, 322.02 examples/s]Converting format of dataset (num_proc=96):   5%|▍         | 1578/33047 [00:08<01:35, 329.80 examples/s]Converting format of dataset (num_proc=96):   5%|▍         | 1638/33047 [00:08<01:18, 400.66 examples/s]Converting format of dataset (num_proc=96):   5%|▌         | 1681/33047 [00:08<01:23, 375.99 examples/s]Converting format of dataset (num_proc=96):   5%|▌         | 1725/33047 [00:08<01:25, 364.83 examples/s]Converting format of dataset (num_proc=96):   5%|▌         | 1783/33047 [00:08<01:15, 413.07 examples/s]Converting format of dataset (num_proc=96):   6%|▌         | 1842/33047 [00:08<01:07, 460.14 examples/s]Converting format of dataset (num_proc=96):   6%|▌         | 1891/33047 [00:09<01:17, 403.32 examples/s]Converting format of dataset (num_proc=96):   6%|▌         | 1934/33047 [00:09<01:16, 407.45 examples/s]Converting format of dataset (num_proc=96):   6%|▌         | 1979/33047 [00:09<01:14, 415.31 examples/s]Converting format of dataset (num_proc=96):   6%|▌         | 2026/33047 [00:09<01:13, 421.91 examples/s]Converting format of dataset (num_proc=96):   6%|▋         | 2082/33047 [00:09<01:08, 451.19 examples/s]Converting format of dataset (num_proc=96):   6%|▋         | 2148/33047 [00:09<01:01, 499.88 examples/s]Converting format of dataset (num_proc=96):   7%|▋         | 2201/33047 [00:09<01:01, 501.74 examples/s]Converting format of dataset (num_proc=96):   7%|▋         | 2259/33047 [00:09<01:00, 506.72 examples/s]Converting format of dataset (num_proc=96):   7%|▋         | 2326/33047 [00:09<00:57, 537.70 examples/s]Converting format of dataset (num_proc=96):   7%|▋         | 2414/33047 [00:09<00:49, 624.19 examples/s]Converting format of dataset (num_proc=96):   8%|▊         | 2488/33047 [00:10<00:47, 648.84 examples/s]Converting format of dataset (num_proc=96):   8%|▊         | 2575/33047 [00:10<00:43, 700.26 examples/s]Converting format of dataset (num_proc=96):   8%|▊         | 2652/33047 [00:10<00:43, 703.35 examples/s]Converting format of dataset (num_proc=96):   8%|▊         | 2764/33047 [00:10<00:36, 819.19 examples/s]Converting format of dataset (num_proc=96):   9%|▊         | 2867/33047 [00:10<00:35, 839.53 examples/s]Converting format of dataset (num_proc=96):   9%|▉         | 2977/33047 [00:10<00:32, 912.98 examples/s]Converting format of dataset (num_proc=96):   9%|▉         | 3078/33047 [00:10<00:31, 939.76 examples/s]Converting format of dataset (num_proc=96):  10%|▉         | 3211/33047 [00:10<00:29, 1023.38 examples/s]Converting format of dataset (num_proc=96):  10%|█         | 3347/33047 [00:10<00:26, 1115.90 examples/s]Converting format of dataset (num_proc=96):  11%|█         | 3473/33047 [00:11<00:25, 1151.46 examples/s]Converting format of dataset (num_proc=96):  11%|█         | 3603/33047 [00:11<00:24, 1182.01 examples/s]Converting format of dataset (num_proc=96):  12%|█▏        | 3824/33047 [00:11<00:19, 1467.83 examples/s]Converting format of dataset (num_proc=96):  12%|█▏        | 4016/33047 [00:11<00:18, 1598.00 examples/s]Converting format of dataset (num_proc=96):  13%|█▎        | 4179/33047 [00:11<00:18, 1588.79 examples/s]Converting format of dataset (num_proc=96):  13%|█▎        | 4343/33047 [00:11<00:18, 1539.73 examples/s]Converting format of dataset (num_proc=96):  14%|█▎        | 4524/33047 [00:11<00:17, 1614.97 examples/s]Converting format of dataset (num_proc=96):  14%|█▍        | 4740/33047 [00:11<00:16, 1727.88 examples/s]Converting format of dataset (num_proc=96):  15%|█▍        | 4956/33047 [00:11<00:15, 1841.01 examples/s]Converting format of dataset (num_proc=96):  16%|█▌        | 5161/33047 [00:11<00:14, 1885.24 examples/s]Converting format of dataset (num_proc=96):  16%|█▌        | 5350/33047 [00:12<00:16, 1714.19 examples/s]Converting format of dataset (num_proc=96):  17%|█▋        | 5543/33047 [00:12<00:15, 1757.85 examples/s]Converting format of dataset (num_proc=96):  17%|█▋        | 5743/33047 [00:12<00:14, 1820.56 examples/s]Converting format of dataset (num_proc=96):  18%|█▊        | 5980/33047 [00:12<00:13, 1972.59 examples/s]Converting format of dataset (num_proc=96):  19%|█▉        | 6268/33047 [00:12<00:12, 2220.59 examples/s]Converting format of dataset (num_proc=96):  20%|█▉        | 6552/33047 [00:12<00:11, 2396.94 examples/s]Converting format of dataset (num_proc=96):  21%|██        | 6797/33047 [00:12<00:10, 2409.74 examples/s]Converting format of dataset (num_proc=96):  21%|██▏       | 7040/33047 [00:12<00:11, 2214.41 examples/s]Converting format of dataset (num_proc=96):  22%|██▏       | 7268/33047 [00:12<00:12, 2135.15 examples/s]Converting format of dataset (num_proc=96):  23%|██▎       | 7488/33047 [00:13<00:12, 2090.44 examples/s]Converting format of dataset (num_proc=96):  23%|██▎       | 7702/33047 [00:13<00:12, 1967.02 examples/s]Converting format of dataset (num_proc=96):  24%|██▍       | 7902/33047 [00:13<00:14, 1694.73 examples/s]Converting format of dataset (num_proc=96):  24%|██▍       | 8079/33047 [00:13<00:18, 1336.91 examples/s]Converting format of dataset (num_proc=96):  25%|██▍       | 8229/33047 [00:13<00:19, 1256.51 examples/s]Converting format of dataset (num_proc=96):  25%|██▌       | 8371/33047 [00:13<00:19, 1275.20 examples/s]Converting format of dataset (num_proc=96):  26%|██▌       | 8548/33047 [00:13<00:17, 1374.25 examples/s]Converting format of dataset (num_proc=96):  26%|██▋       | 8696/33047 [00:14<00:17, 1357.78 examples/s]Converting format of dataset (num_proc=96):  27%|██▋       | 8840/33047 [00:14<00:25, 957.79 examples/s] Converting format of dataset (num_proc=96):  27%|██▋       | 8956/33047 [00:14<00:29, 824.99 examples/s]Converting format of dataset (num_proc=96):  27%|██▋       | 9056/33047 [00:14<00:29, 800.58 examples/s]Converting format of dataset (num_proc=96):  28%|██▊       | 9146/33047 [00:14<00:31, 762.14 examples/s]Converting format of dataset (num_proc=96):  28%|██▊       | 9253/33047 [00:14<00:28, 826.38 examples/s]Converting format of dataset (num_proc=96):  28%|██▊       | 9348/33047 [00:15<00:28, 832.75 examples/s]Converting format of dataset (num_proc=96):  29%|██▊       | 9437/33047 [00:15<00:36, 653.36 examples/s]Converting format of dataset (num_proc=96):  29%|██▉       | 9511/33047 [00:15<00:35, 669.35 examples/s]Converting format of dataset (num_proc=96):  29%|██▉       | 9604/33047 [00:15<00:32, 727.09 examples/s]Converting format of dataset (num_proc=96):  29%|██▉       | 9685/33047 [00:15<00:35, 656.46 examples/s]Converting format of dataset (num_proc=96):  30%|██▉       | 9757/33047 [00:15<00:37, 618.18 examples/s]Converting format of dataset (num_proc=96):  30%|██▉       | 9823/33047 [00:15<00:39, 588.41 examples/s]Converting format of dataset (num_proc=96):  30%|██▉       | 9889/33047 [00:16<00:45, 511.13 examples/s]Converting format of dataset (num_proc=96):  30%|███       | 9974/33047 [00:16<00:42, 547.40 examples/s]Converting format of dataset (num_proc=96):  30%|███       | 10032/33047 [00:16<00:48, 477.79 examples/s]Converting format of dataset (num_proc=96):  31%|███       | 10125/33047 [00:16<00:40, 567.29 examples/s]Converting format of dataset (num_proc=96):  31%|███       | 10197/33047 [00:16<00:39, 582.11 examples/s]Converting format of dataset (num_proc=96):  31%|███       | 10276/33047 [00:16<00:36, 626.09 examples/s]Converting format of dataset (num_proc=96):  31%|███▏      | 10375/33047 [00:16<00:31, 709.24 examples/s]Converting format of dataset (num_proc=96):  32%|███▏      | 10449/33047 [00:16<00:36, 618.08 examples/s]Converting format of dataset (num_proc=96):  32%|███▏      | 10517/33047 [00:17<00:39, 566.02 examples/s]Converting format of dataset (num_proc=96):  32%|███▏      | 10579/33047 [00:17<00:42, 526.44 examples/s]Converting format of dataset (num_proc=96):  32%|███▏      | 10681/33047 [00:17<00:36, 610.03 examples/s]Converting format of dataset (num_proc=96):  33%|███▎      | 10746/33047 [00:17<00:36, 608.56 examples/s]Converting format of dataset (num_proc=96):  33%|███▎      | 10844/33047 [00:17<00:31, 698.80 examples/s]Converting format of dataset (num_proc=96):  33%|███▎      | 10917/33047 [00:17<00:32, 687.96 examples/s]Converting format of dataset (num_proc=96):  33%|███▎      | 11002/33047 [00:17<00:30, 728.39 examples/s]Converting format of dataset (num_proc=96):  34%|███▎      | 11121/33047 [00:17<00:26, 841.74 examples/s]Converting format of dataset (num_proc=96):  34%|███▍      | 11210/33047 [00:17<00:26, 829.41 examples/s]Converting format of dataset (num_proc=96):  34%|███▍      | 11334/33047 [00:18<00:23, 935.16 examples/s]Converting format of dataset (num_proc=96):  35%|███▍      | 11430/33047 [00:18<00:23, 938.83 examples/s]Converting format of dataset (num_proc=96):  35%|███▍      | 11525/33047 [00:18<00:23, 911.67 examples/s]Converting format of dataset (num_proc=96):  35%|███▌      | 11660/33047 [00:18<00:21, 999.65 examples/s]Converting format of dataset (num_proc=96):  36%|███▌      | 11804/33047 [00:18<00:18, 1122.04 examples/s]Converting format of dataset (num_proc=96):  36%|███▋      | 11991/33047 [00:18<00:15, 1328.02 examples/s]Converting format of dataset (num_proc=96):  37%|███▋      | 12147/33047 [00:18<00:15, 1390.97 examples/s]Converting format of dataset (num_proc=96):  37%|███▋      | 12299/33047 [00:18<00:14, 1425.47 examples/s]Converting format of dataset (num_proc=96):  38%|███▊      | 12519/33047 [00:18<00:12, 1633.27 examples/s]Converting format of dataset (num_proc=96):  39%|███▉      | 12817/33047 [00:19<00:10, 1994.70 examples/s]Converting format of dataset (num_proc=96):  40%|████      | 13232/33047 [00:19<00:07, 2581.17 examples/s]Converting format of dataset (num_proc=96):  41%|████▏     | 13706/33047 [00:19<00:06, 3208.27 examples/s]Converting format of dataset (num_proc=96):  43%|████▎     | 14173/33047 [00:19<00:05, 3610.17 examples/s]Converting format of dataset (num_proc=96):  44%|████▍     | 14703/33047 [00:19<00:04, 4093.25 examples/s]Converting format of dataset (num_proc=96):  47%|████▋     | 15428/33047 [00:19<00:03, 5005.98 examples/s]Converting format of dataset (num_proc=96):  49%|████▉     | 16309/33047 [00:19<00:02, 6115.77 examples/s]Converting format of dataset (num_proc=96):  52%|█████▏    | 17236/33047 [00:19<00:02, 7044.93 examples/s]Converting format of dataset (num_proc=96):  55%|█████▍    | 18083/33047 [00:19<00:02, 7455.51 examples/s]Converting format of dataset (num_proc=96):  57%|█████▋    | 18962/33047 [00:19<00:01, 7850.60 examples/s]Converting format of dataset (num_proc=96):  60%|██████    | 19871/33047 [00:20<00:01, 8178.58 examples/s]Converting format of dataset (num_proc=96):  63%|██████▎   | 20747/33047 [00:20<00:01, 8301.10 examples/s]Converting format of dataset (num_proc=96):  65%|██████▌   | 21635/33047 [00:20<00:01, 8435.92 examples/s]Converting format of dataset (num_proc=96):  68%|██████▊   | 22529/33047 [00:20<00:01, 8573.84 examples/s]Converting format of dataset (num_proc=96):  71%|███████   | 23398/33047 [00:20<00:01, 8598.32 examples/s]Converting format of dataset (num_proc=96):  74%|███████▎  | 24313/33047 [00:20<00:00, 8761.22 examples/s]Converting format of dataset (num_proc=96):  76%|███████▋  | 25225/33047 [00:20<00:00, 8841.94 examples/s]Converting format of dataset (num_proc=96):  79%|███████▉  | 26193/33047 [00:20<00:00, 9079.41 examples/s]Converting format of dataset (num_proc=96):  82%|████████▏ | 27102/33047 [00:20<00:00, 8946.51 examples/s]Converting format of dataset (num_proc=96):  85%|████████▍ | 28003/33047 [00:20<00:00, 8851.60 examples/s]Converting format of dataset (num_proc=96):  87%|████████▋ | 28889/33047 [00:21<00:00, 8636.27 examples/s]Converting format of dataset (num_proc=96):  90%|█████████ | 29755/33047 [00:21<00:00, 7527.47 examples/s]Converting format of dataset (num_proc=96):  92%|█████████▏| 30533/33047 [00:21<00:00, 6740.59 examples/s]Converting format of dataset (num_proc=96):  95%|█████████▍| 31237/33047 [00:21<00:00, 6046.62 examples/s]Converting format of dataset (num_proc=96):  96%|█████████▋| 31874/33047 [00:21<00:00, 5236.46 examples/s]Converting format of dataset (num_proc=96):  98%|█████████▊| 32429/33047 [00:21<00:00, 3971.92 examples/s]Converting format of dataset (num_proc=96): 100%|█████████▉| 32885/33047 [00:22<00:00, 2988.14 examples/s]Converting format of dataset (num_proc=96): 100%|██████████| 33047/33047 [00:22<00:00, 1450.46 examples/s]
[rank0]:[W1113 07:27:09.882338504 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'parquet' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Running tokenizer on dataset (num_proc=96):   0%|          | 0/33047 [00:00<?, ? examples/s][WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:03,479 >> Token indices sequence length is longer than the specified maximum sequence length for this model (131574 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:05,300 >> Token indices sequence length is longer than the specified maximum sequence length for this model (134772 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:06,317 >> Token indices sequence length is longer than the specified maximum sequence length for this model (137167 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:10,482 >> Token indices sequence length is longer than the specified maximum sequence length for this model (162967 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:13,913 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147318 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:15,670 >> Token indices sequence length is longer than the specified maximum sequence length for this model (159221 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:24,678 >> Token indices sequence length is longer than the specified maximum sequence length for this model (194018 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:30,805 >> Token indices sequence length is longer than the specified maximum sequence length for this model (133620 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:33,308 >> Token indices sequence length is longer than the specified maximum sequence length for this model (141021 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:34,070 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147419 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:35,019 >> Token indices sequence length is longer than the specified maximum sequence length for this model (225171 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:41,955 >> Token indices sequence length is longer than the specified maximum sequence length for this model (165020 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:43,987 >> Token indices sequence length is longer than the specified maximum sequence length for this model (152873 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:47,432 >> Token indices sequence length is longer than the specified maximum sequence length for this model (165016 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:52,129 >> Token indices sequence length is longer than the specified maximum sequence length for this model (193772 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:53,828 >> Token indices sequence length is longer than the specified maximum sequence length for this model (131569 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:58,286 >> Token indices sequence length is longer than the specified maximum sequence length for this model (137168 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:28:59,843 >> Token indices sequence length is longer than the specified maximum sequence length for this model (267369 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:00,958 >> Token indices sequence length is longer than the specified maximum sequence length for this model (149570 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:02,725 >> Token indices sequence length is longer than the specified maximum sequence length for this model (176424 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:03,494 >> Token indices sequence length is longer than the specified maximum sequence length for this model (222674 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:05,858 >> Token indices sequence length is longer than the specified maximum sequence length for this model (233569 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:07,247 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147322 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:08,865 >> Token indices sequence length is longer than the specified maximum sequence length for this model (193772 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:10,980 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147422 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:12,116 >> Token indices sequence length is longer than the specified maximum sequence length for this model (168365 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:12,170 >> Token indices sequence length is longer than the specified maximum sequence length for this model (233571 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:15,470 >> Token indices sequence length is longer than the specified maximum sequence length for this model (160316 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:15,484 >> Token indices sequence length is longer than the specified maximum sequence length for this model (259673 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:20,279 >> Token indices sequence length is longer than the specified maximum sequence length for this model (169918 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:20,386 >> Token indices sequence length is longer than the specified maximum sequence length for this model (169921 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:20,566 >> Token indices sequence length is longer than the specified maximum sequence length for this model (233572 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:23,714 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147173 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:24,843 >> Token indices sequence length is longer than the specified maximum sequence length for this model (132318 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:31,317 >> Token indices sequence length is longer than the specified maximum sequence length for this model (136720 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:37,689 >> Token indices sequence length is longer than the specified maximum sequence length for this model (193771 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:40,492 >> Token indices sequence length is longer than the specified maximum sequence length for this model (187823 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:44,007 >> Token indices sequence length is longer than the specified maximum sequence length for this model (275421 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:44,736 >> Token indices sequence length is longer than the specified maximum sequence length for this model (229127 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:46,168 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147420 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:53,913 >> Token indices sequence length is longer than the specified maximum sequence length for this model (137178 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:54,076 >> Token indices sequence length is longer than the specified maximum sequence length for this model (208121 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:54,776 >> Token indices sequence length is longer than the specified maximum sequence length for this model (164824 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:56,486 >> Token indices sequence length is longer than the specified maximum sequence length for this model (176420 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:29:58,534 >> Token indices sequence length is longer than the specified maximum sequence length for this model (382175 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:01,413 >> Token indices sequence length is longer than the specified maximum sequence length for this model (275418 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:23,278 >> Token indices sequence length is longer than the specified maximum sequence length for this model (148222 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:23,481 >> Token indices sequence length is longer than the specified maximum sequence length for this model (275418 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:31,386 >> Token indices sequence length is longer than the specified maximum sequence length for this model (148221 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:32,205 >> Token indices sequence length is longer than the specified maximum sequence length for this model (193772 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:33,168 >> Token indices sequence length is longer than the specified maximum sequence length for this model (146218 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:35,549 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147916 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:38,786 >> Token indices sequence length is longer than the specified maximum sequence length for this model (185421 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:48,353 >> Token indices sequence length is longer than the specified maximum sequence length for this model (382168 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:30:59,161 >> Token indices sequence length is longer than the specified maximum sequence length for this model (149065 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:06,664 >> Token indices sequence length is longer than the specified maximum sequence length for this model (137178 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:08,583 >> Token indices sequence length is longer than the specified maximum sequence length for this model (222665 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:09,868 >> Token indices sequence length is longer than the specified maximum sequence length for this model (232418 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:10,176 >> Token indices sequence length is longer than the specified maximum sequence length for this model (221968 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:14,662 >> Token indices sequence length is longer than the specified maximum sequence length for this model (232620 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:16,524 >> Token indices sequence length is longer than the specified maximum sequence length for this model (162974 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:32,411 >> Token indices sequence length is longer than the specified maximum sequence length for this model (211969 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:34,311 >> Token indices sequence length is longer than the specified maximum sequence length for this model (259672 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:34,763 >> Token indices sequence length is longer than the specified maximum sequence length for this model (218871 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:36,640 >> Token indices sequence length is longer than the specified maximum sequence length for this model (146569 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:39,333 >> Token indices sequence length is longer than the specified maximum sequence length for this model (278920 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:45,287 >> Token indices sequence length is longer than the specified maximum sequence length for this model (142718 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:47,006 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147920 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:31:49,769 >> Token indices sequence length is longer than the specified maximum sequence length for this model (232421 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:03,412 >> Token indices sequence length is longer than the specified maximum sequence length for this model (187820 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:05,054 >> Token indices sequence length is longer than the specified maximum sequence length for this model (227572 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:14,367 >> Token indices sequence length is longer than the specified maximum sequence length for this model (275417 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:18,559 >> Token indices sequence length is longer than the specified maximum sequence length for this model (136716 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:21,895 >> Token indices sequence length is longer than the specified maximum sequence length for this model (208118 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:24,516 >> Token indices sequence length is longer than the specified maximum sequence length for this model (267371 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:36,189 >> Token indices sequence length is longer than the specified maximum sequence length for this model (232420 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:40,649 >> Token indices sequence length is longer than the specified maximum sequence length for this model (315318 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:43,876 >> Token indices sequence length is longer than the specified maximum sequence length for this model (151721 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:49,732 >> Token indices sequence length is longer than the specified maximum sequence length for this model (214721 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:51,594 >> Token indices sequence length is longer than the specified maximum sequence length for this model (209375 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:51,993 >> Token indices sequence length is longer than the specified maximum sequence length for this model (160320 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:32:58,871 >> Token indices sequence length is longer than the specified maximum sequence length for this model (221975 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:33:30,773 >> Token indices sequence length is longer than the specified maximum sequence length for this model (238217 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:33:39,590 >> Token indices sequence length is longer than the specified maximum sequence length for this model (208121 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:33:47,675 >> Token indices sequence length is longer than the specified maximum sequence length for this model (147429 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:34:15,316 >> Token indices sequence length is longer than the specified maximum sequence length for this model (142717 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:34:29,099 >> Token indices sequence length is longer than the specified maximum sequence length for this model (151873 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:34:37,402 >> Token indices sequence length is longer than the specified maximum sequence length for this model (163668 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:35:12,684 >> Token indices sequence length is longer than the specified maximum sequence length for this model (163673 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:35:17,584 >> Token indices sequence length is longer than the specified maximum sequence length for this model (131721 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:35:28,920 >> Token indices sequence length is longer than the specified maximum sequence length for this model (173621 > 131072). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:4009] 2025-11-13 07:35:33,304 >> Token indices sequence length is longer than the specified maximum sequence length for this model (194022 > 131072). Running this sequence through the model will result in indexing errors
slurmstepd: error: *** JOB 85978 ON trig0034 CANCELLED AT 2025-11-13T07:36:31 DUE TO TIME LIMIT ***

scontrol show job 85978
JobId=85978 JobName=slurm_qwen2_5vl_lora_sft_SQA3D.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=330532 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=TimeLimit Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:15
   RunTime=00:10:21 TimeLimit=00:10:00 TimeMin=N/A
   SubmitTime=2025-11-13T06:44:55 EligibleTime=2025-11-13T06:44:55
   AccrueTime=2025-11-13T06:44:55
   StartTime=2025-11-13T07:26:10 EndTime=2025-11-13T07:36:31 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-13T07:26:10 Scheduler=Main
   Partition=compute_full_node AllocNode:Sid=trig-login01:731173
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0034
   BatchHost=trig0034
   NumNodes=1 NumCPUs=96 NumTasks=1 CPUs/Task=96 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   AllocTRES=cpu=96,mem=770000M,node=1,billing=4,gres/gpu=4
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=96 MinMemoryNode=770000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=./slurm_qwen2_5vl_lora_sft_SQA3D.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L ./slurm_qwen2_5vl_lora_sft_SQA3D.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85978.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85978.out
   TresPerNode=gres/gpu:h100:4
   TresPerTask=cpu=96
   

sacct -j 85978
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
85978        slurm_qwe+ def-wangcs   00:10:21                         01:33:29   12:33:44      0:0 
85978.batch       batch def-wangcs   00:10:27          0 299049644K   01:33:29   12:33:44     0:15 
85978.extern     extern def-wangcs   00:10:27          0        68K  00:00.001   00:00:00      0:0 

