
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[2025-11-13 04:21:51,136] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/app/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/app/src/llamafactory/launcher.py", line 152, in launch
    run_exp()
  File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
    _training_function(config={"args": args, "callbacks": callbacks})
  File "/app/src/llamafactory/train/tuner.py", line 55, in _training_function
    model_args, data_args, training_args, finetuning_args, generating_args = get_train_args(args)
                                                                             ^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/hparams/parser.py", line 219, in get_train_args
    model_args, data_args, training_args, finetuning_args, generating_args = _parse_train_args(args)
                                                                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/hparams/parser.py", line 197, in _parse_train_args
    return _parse_args(parser, args, allow_extra_keys=allow_extra_keys)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/hparams/parser.py", line 79, in _parse_args
    return parser.parse_dict(args, allow_extra_keys=allow_extra_keys)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/transformers/hf_argparser.py", line 380, in parse_dict
    obj = dtype(**inputs)
          ^^^^^^^^^^^^^^^
  File "<string>", line 30, in __init__
  File "/app/src/llamafactory/hparams/data_args.py", line 174, in __post_init__
    raise ValueError("`max_samples` is incompatible with `streaming`.")
ValueError: `max_samples` is incompatible with `streaming`.
INFO:    Terminating fuse-overlayfs after timeout
INFO:    Timeouts can be caused by a running background process

scontrol show job 85920
JobId=85920 JobName=slurm_qwen2_5vl_lora_sft_SQA3D.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=329757 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:27 TimeLimit=00:25:00 TimeMin=N/A
   SubmitTime=2025-11-13T04:21:30 EligibleTime=2025-11-13T04:21:30
   AccrueTime=2025-11-13T04:21:30
   StartTime=2025-11-13T04:21:30 EndTime=2025-11-13T04:21:57 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-13T04:21:30 Scheduler=Main
   Partition=compute AllocNode:Sid=trig-login01:731173
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0044
   BatchHost=trig0044
   NumNodes=1 NumCPUs=24 NumTasks=1 CPUs/Task=24 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=24,mem=192500M,node=1,billing=1,gres/gpu=1
   AllocTRES=cpu=24,mem=192500M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=24 MinMemoryNode=192500M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=./slurm_qwen2_5vl_lora_sft_SQA3D.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L ./slurm_qwen2_5vl_lora_sft_SQA3D.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85920.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft_SQA3D/%N-qwen2_5vl_lora_sft_SQA3D-85920.out
   TresPerNode=gres/gpu:h100:1
   TresPerTask=cpu=24
   

sacct -j 85920
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
85920        slurm_qwe+ def-wangcs   00:00:28                         00:00:00   00:00:00      0:0 
85920.batch       batch def-wangcs   00:00:28                         00:00:00   00:00:00      0:0 
85920.extern     extern def-wangcs   00:00:28                         00:00:00   00:00:00      0:0 

