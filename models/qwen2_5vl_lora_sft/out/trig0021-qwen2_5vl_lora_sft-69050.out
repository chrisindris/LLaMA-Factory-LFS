
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[2025-11-02 03:30:53,844] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[INFO|2025-11-02 03:30:56] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16
Traceback (most recent call last):
  File "/app/src/llamafactory/model/loader.py", line 78, in load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 1140, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2038, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py", line 167, in list_repo_templates
    return [
           ^
  File "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py", line 167, in <listcomp>
    return [
           ^
  File "/opt/conda/lib/python3.11/site-packages/huggingface_hub/hf_api.py", line 3188, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
  File "/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 95, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/requests/adapters.py", line 639, in send
    self.cert_verify(conn, request.url, verify, cert)
  File "/opt/conda/lib/python3.11/site-packages/requests/adapters.py", line 328, in cert_verify
    raise OSError(
OSError: Could not find a suitable TLS CA certificate bundle, invalid path: /etc/pki/tls/certs/ca-bundle.crt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/app/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/app/src/llamafactory/launcher.py", line 152, in launch
    run_exp()
  File "/app/src/llamafactory/train/tuner.py", line 110, in run_exp
    _training_function(config={"args": args, "callbacks": callbacks})
  File "/app/src/llamafactory/train/tuner.py", line 72, in _training_function
    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
  File "/app/src/llamafactory/train/sft/workflow.py", line 48, in run_sft
    tokenizer_module = load_tokenizer(model_args)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/llamafactory/model/loader.py", line 93, in load_tokenizer
    raise OSError("Failed to load tokenizer.") from e
OSError: Failed to load tokenizer.

scontrol show job 69050
JobId=69050 JobName=slurm_qwen2_5vl_lora_sft.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=248785 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=NonZeroExitCode Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=1:0
   RunTime=00:00:27 TimeLimit=00:02:00 TimeMin=N/A
   SubmitTime=2025-11-02T03:30:18 EligibleTime=2025-11-02T03:30:18
   AccrueTime=2025-11-02T03:30:18
   StartTime=2025-11-02T03:30:32 EndTime=2025-11-02T03:30:59 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-02T03:30:32 Scheduler=Backfill
   Partition=compute AllocNode:Sid=trig-login01:2125035
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0021
   BatchHost=trig0021
   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=1,mem=192500M,node=1,billing=1,gres/gpu=1
   AllocTRES=cpu=1,mem=192500M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=1 MinMemoryNode=192500M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/slurm_qwen2_5vl_lora_sft.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L slurm_qwen2_5vl_lora_sft.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/%N-qwen2_5vl_lora_sft-69050.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/%N-qwen2_5vl_lora_sft-69050.out
   TresPerNode=gres/gpu:h100:1
   TresPerTask=cpu=1
   

sacct -j 69050
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
69050        slurm_qwe+ def-wangcs   00:00:27                         00:00:00   00:00:00      0:0 
69050.batch       batch def-wangcs   00:00:27                         00:00:00   00:00:00      0:0 
69050.extern     extern def-wangcs   00:00:27                         00:00:00   00:00:00      0:0 

