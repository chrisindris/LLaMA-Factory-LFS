
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

[2025-11-02 03:58:56,372] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.11/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[INFO|2025-11-02 03:58:59] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16
[INFO|hub.py:421] 2025-11-02 03:58:59,544 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2025-11-02 03:58:59,559 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,568 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-02 03:58:59,818 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2025-11-02 03:58:59,818 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2025-11-02 03:58:59,819 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2025-11-02 03:58:59,822 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-02 03:58:59,824 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:316] 2025-11-02 03:58:59,827 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2025-11-02 03:58:59,828 >> loading configuration file preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-11-02 03:58:59,836 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2025-11-02 03:58:59,836 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file vocab.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file merges.txt from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file tokenizer.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file tokenizer_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-11-02 03:58:59,840 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-11-02 03:59:00,046 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2025-11-02 03:59:00,047 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2025-11-02 03:59:00,050 >> loading configuration file video_preprocessor_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-11-02 03:59:00,053 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-11-02 03:59:00,053 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2025-11-02 03:59:00,059 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2025-11-02 03:59:00,440 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

[INFO|2025-11-02 03:59:00] llamafactory.data.loader:143 >> Loading dataset mllm_demo.json...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
num_proc must be <= 6. Reducing num_proc to 6 for dataset of size 6.
Converting format of dataset (num_proc=6): 100%|██████████| 6/6 [00:00<?, ? examples/s]Converting format of dataset (num_proc=6): 7 examples [00:00,  5.05 examples/s]        Converting format of dataset (num_proc=6): 12 examples [00:00, 14.65 examples/s]
[INFO|2025-11-02 03:59:00] llamafactory.data.loader:143 >> Loading dataset identity.json...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Converting format of dataset (num_proc=16): 100%|██████████| 91/91 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 97 examples [00:00, 15.78 examples/s]         Converting format of dataset (num_proc=16): 182 examples [00:00, 111.18 examples/s]
[INFO|2025-11-02 03:59:01] llamafactory.data.loader:143 >> Loading dataset alpaca_en_demo.json...
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Converting format of dataset (num_proc=16): 100%|██████████| 999/999 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 1062 examples [00:00, 138.59 examples/s]        Converting format of dataset (num_proc=16): 1998 examples [00:00, 1174.75 examples/s]
Running tokenizer on dataset (num_proc=16): 100%|██████████| 1096/1096 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16): 1165 examples [00:02, 26.13 examples/s]           Running tokenizer on dataset (num_proc=16): 1234 examples [00:03, 48.84 examples/s]Running tokenizer on dataset (num_proc=16): 1303 examples [00:03, 67.28 examples/s]Running tokenizer on dataset (num_proc=16): 1372 examples [00:04, 81.78 examples/s]Running tokenizer on dataset (num_proc=16): 1510 examples [00:04, 125.84 examples/s]Running tokenizer on dataset (num_proc=16): 1579 examples [00:05, 127.28 examples/s]Running tokenizer on dataset (num_proc=16): 1648 examples [00:06, 121.57 examples/s]Running tokenizer on dataset (num_proc=16): 1716 examples [00:06, 115.43 examples/s]Running tokenizer on dataset (num_proc=16): 1784 examples [00:07, 114.65 examples/s]Running tokenizer on dataset (num_proc=16): 1852 examples [00:07, 117.62 examples/s]Running tokenizer on dataset (num_proc=16): 1920 examples [00:08, 125.98 examples/s]Running tokenizer on dataset (num_proc=16): 1988 examples [00:08, 134.69 examples/s]Running tokenizer on dataset (num_proc=16): 2056 examples [00:09, 154.92 examples/s]Running tokenizer on dataset (num_proc=16): 2124 examples [00:09, 187.18 examples/s]Running tokenizer on dataset (num_proc=16): 2192 examples [00:09, 238.51 examples/s]Running tokenizer on dataset (num_proc=16): 2192 examples [00:09, 111.94 examples/s]
[INFO|hub.py:421] 2025-11-02 03:59:12,610 >> Offline mode: forcing local_files_only=True
[INFO|configuration_utils.py:765] 2025-11-02 03:59:12,614 >> loading configuration file config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
[INFO|configuration_utils.py:839] 2025-11-02 03:59:12,617 >> Model config Qwen2_5_VLConfig {
  "architectures": [
    "Qwen2_5_VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "dtype": "bfloat16",
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 128000,
  "max_window_layers": 28,
  "model_type": "qwen2_5_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "_name_or_path": "Qwen/Qwen2.5-VL-7B-Instruct",
    "architectures": [
      "Qwen2_5_VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "dtype": "bfloat16",
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "layer_types": [
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention"
    ],
    "max_position_embeddings": 128000,
    "max_window_layers": 28,
    "model_type": "qwen2_5_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "use_cache": true,
    "use_sliding_window": false,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "transformers_version": "4.57.0",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "fullatt_block_indexes": [
      7,
      15,
      23,
      31
    ],
    "hidden_act": "silu",
    "hidden_size": 1280,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "intermediate_size": 3420,
    "model_type": "qwen2_5_vl",
    "num_heads": 16,
    "out_hidden_size": 3584,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "tokens_per_second": 2,
    "window_size": 112
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 15191, 525, 807, 30, 151645, 198, 151644, 77091, 198, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, 198, 151644, 872, 198, 3838, 525, 807, 3730, 30, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 151645, 198, 151644, 77091, 198, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Who are they?<|im_end|>
<|im_start|>assistant
They're Kane and Gretzka from Bayern Munich.<|im_end|>
<|im_start|>user
What are they doing?<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|><|im_end|>
<|im_start|>assistant
They are celebrating on the soccer field.<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, 198, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645, 198]
labels:
They're Kane and Gretzka from Bayern Munich.<|im_end|>
They are celebrating on the soccer field.<|im_end|>

[INFO|2025-11-02 03:59:12] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|hub.py:421] 2025-11-02 03:59:12,708 >> Offline mode: forcing local_files_only=True
[WARNING|logging.py:328] 2025-11-02 03:59:12,721 >> `torch_dtype` is deprecated! Use `dtype` instead!
[INFO|hub.py:421] 2025-11-02 03:59:12,721 >> Offline mode: forcing local_files_only=True
[INFO|modeling_utils.py:4840] 2025-11-02 03:59:12,722 >> Offline mode: forcing local_files_only=True
[INFO|modeling_utils.py:1176] 2025-11-02 03:59:12,725 >> loading weights file model.safetensors from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
[INFO|modeling_utils.py:2345] 2025-11-02 03:59:12,732 >> Instantiating Qwen2_5_VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2025-11-02 03:59:12,734 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2345] 2025-11-02 03:59:12,735 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2345] 2025-11-02 03:59:12,759 >> Instantiating Qwen2_5_VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:11<00:46, 11.69s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:28<00:43, 14.65s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:40<00:26, 13.31s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:53<00:13, 13.19s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:56<00:00,  9.59s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:56<00:00, 11.27s/it]
[INFO|configuration_utils.py:941] 2025-11-02 04:00:09,343 >> loading configuration file generation_config.json from cache at /scratch/indrisch/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
[INFO|configuration_utils.py:986] 2025-11-02 04:00:09,344 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.05,
  "temperature": 1e-06
}

[INFO|dynamic_module_utils.py:423] 2025-11-02 04:00:09,345 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-VL-7B-Instruct.
[INFO|2025-11-02 04:00:09] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-11-02 04:00:09] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-11-02 04:00:09] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.
[INFO|2025-11-02 04:00:09] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA
[INFO|2025-11-02 04:00:09] llamafactory.model.model_utils.misc:143 >> Found linear modules: down_proj,o_proj,q_proj,v_proj,gate_proj,up_proj,k_proj
[INFO|2025-11-02 04:00:09] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks'].
[INFO|2025-11-02 04:00:09] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.
[INFO|2025-11-02 04:00:09] llamafactory.model.loader:143 >> trainable params: 20,185,088 || all params: 8,312,351,744 || trainable%: 0.2428
[WARNING|trainer.py:906] 2025-11-02 04:00:09,723 >> The model is already on multiple devices. Skipping the move to device specified in `args`.
[INFO|trainer.py:749] 2025-11-02 04:00:09,730 >> Using auto half precision backend
[WARNING|trainer.py:982] 2025-11-02 04:00:09,731 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
[DEBUG|trainer.py:2373] 2025-11-02 04:00:10,062 >> Currently training with a batch size of: 1
/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|trainer.py:2519] 2025-11-02 04:00:10,144 >> ***** Running training *****
[INFO|trainer.py:2520] 2025-11-02 04:00:10,144 >>   Num examples = 1,096
[INFO|trainer.py:2521] 2025-11-02 04:00:10,144 >>   Num Epochs = 3
[INFO|trainer.py:2522] 2025-11-02 04:00:10,144 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2525] 2025-11-02 04:00:10,144 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:2526] 2025-11-02 04:00:10,144 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2527] 2025-11-02 04:00:10,144 >>   Total optimization steps = 411
[INFO|trainer.py:2528] 2025-11-02 04:00:10,149 >>   Number of trainable parameters = 20,185,088
name: base_model.model.model.visual.patch_embed.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.0.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.1.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.2.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.3.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.4.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.5.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.6.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.7.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.8.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.9.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.10.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.11.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.12.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.13.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.14.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.15.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.16.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.17.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.18.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.19.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.20.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.21.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.22.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.23.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.24.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.25.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.26.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.27.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.28.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.29.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.30.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.attn.qkv.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.attn.qkv.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.blocks.31.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.merger.ln_q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.merger.mlp.0.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.merger.mlp.0.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.merger.mlp.2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.visual.merger.mlp.2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.embed_tokens.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.0.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.0.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.1.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.1.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.2.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.2.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.3.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.3.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.4.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.4.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.5.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.5.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.6.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.6.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.7.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.7.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.8.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.8.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.9.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.9.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.10.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.10.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.11.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.11.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.12.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.12.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.13.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.13.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.14.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.14.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.15.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.15.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.16.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.16.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.17.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.17.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.18.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.18.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.19.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.19.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.20.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.20.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.21.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.21.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.22.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.22.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.23.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.23.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.24.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.24.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.25.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.25.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.26.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.26.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.language_model.layers.27.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.layers.27.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.language_model.norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.lm_head.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
  0%|          | 0/411 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1171: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/indrisch/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:1442.)
  split_sizes = (image_grid_thw.prod(-1) // self.visual.spatial_merge_size**2).tolist()
  0%|          | 1/411 [00:14<1:40:47, 14.75s/it]  0%|          | 2/411 [00:25<1:23:23, 12.23s/it]  1%|          | 3/411 [00:35<1:17:35, 11.41s/it]  1%|          | 4/411 [00:45<1:14:01, 10.91s/it]slurmstepd: error: *** JOB 69069 ON trig0012 CANCELLED AT 2025-11-02T04:01:00 DUE TO TIME LIMIT ***

scontrol show job 69069
JobId=69069 JobName=slurm_qwen2_5vl_lora_sft.sh
   UserId=indrisch(3122343) GroupId=indrisch(3122343) MCS_label=N/A
   Priority=248785 Nice=0 Account=def-wangcs QOS=normal
   JobState=COMPLETING Reason=TimeLimit Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:15
   RunTime=00:02:25 TimeLimit=00:02:00 TimeMin=N/A
   SubmitTime=2025-11-02T03:58:34 EligibleTime=2025-11-02T03:58:34
   AccrueTime=2025-11-02T03:58:34
   StartTime=2025-11-02T03:58:35 EndTime=2025-11-02T04:01:00 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-02T03:58:35 Scheduler=Backfill
   Partition=compute AllocNode:Sid=trig-login01:2125035
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=trig0012
   BatchHost=trig0012
   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=1,mem=192500M,node=1,billing=1,gres/gpu=1
   AllocTRES=cpu=1,mem=192500M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=1 MinMemoryNode=192500M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/slurm_qwen2_5vl_lora_sft.sh
   WorkDir=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L slurm_qwen2_5vl_lora_sft.sh 
   StdErr=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/%N-qwen2_5vl_lora_sft-69069.out
   StdIn=/dev/null
   StdOut=/scratch/indrisch/LLaMA-Factory/preliminaries/qwen2_5vl_lora_sft/%N-qwen2_5vl_lora_sft-69069.out
   TresPerNode=gres/gpu:h100:1
   TresPerTask=cpu=1
   

sacct -j 69069
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
69069        slurm_qwe+ def-wangcs   00:02:25                        00:16.043  01:07.102      0:0 
69069.batch       batch def-wangcs   00:02:26          0  19169704K  00:16.043  01:07.101     0:15 
69069.extern     extern def-wangcs   00:02:26          0       196K   00:00:00  00:00.001      0:0 

